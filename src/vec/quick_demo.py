import torch
import gensim

model = gensim.models.Word2Vec.load("./models/custom_w2v_intersect_GoogleNews")
model.init_sims(replace=True) #precomputed l2 normed vectors in-place â€“ saving the extra RAM
print(model.vocabulary.sorted_vocab) # should be True
print(model.wv.vectors.shape)
print(list(model.wv.vocab.keys()))
print(model.wv.similarity('hello', '<person>'))
result = model.wv.similar_by_word("<person>")
print('most similar to <person> :')
for i in range(10):
    most_similar_key, similarity = result[i]  # look at the first match
    print(f"{most_similar_key}: {similarity:.4f}")


"""
d = torch.load('./dat/processed/padded_vectorized_states.pt') #, map_location=lambda storage, loc: storage.cuda(1))
d2 = torch.load('./dat/processed/vectorized_states.pt')
raw = torch.load('./dat/processed/raw_states.pt') #, map_location=lambda storage, loc: storage.cuda(1))

for index, vects in d2.items():
    input_state, next_state = vects[0], vects[1]
    raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]
    print(raw_input_state,"\n", vects[0])
    print(raw_next_state,"\n", vects[1])

    if index > 1:
        break

for index, vects in d.items():
    input_state, next_state = vects[0], vects[1]
    raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]
    print(raw_input_state,"\n", vects[0])
    print(raw_next_state,"\n", vects[1])

    if index > 1:
        break
"""
