{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "#model = gensim.models.Word2Vec.load(\"../models/custom_w2v\")\n",
    "w2v_model = gensim.models.Word2Vec.load(\"../models/custom_w2v_intersect_GoogleNews\")\n",
    "w2v_model.init_sims(replace=True) #precomputed l2 normed vectors in-place – saving the extra RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAIL import get_cosine_sim, get_action, get_raw_action\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.load('../dat/processed/padded_vectorized_states_v3.pt')\n",
    "#d = torch.load('../dat/processed/vectorized_states_v3.pt')\n",
    "raw = torch.load('../dat/processed/raw_states_v3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "go find one .\ntensor([ 51, 217, 105,   0,   0])\n<person> 's name .\ntensor([  5,   8, 170,   0,   0])\n"
     ]
    }
   ],
   "source": [
    "for index, vects in d.items():\n",
    "    # each is N x 300\n",
    "    input_state, next_state = vects[0], vects[1]\n",
    "    # raw strings corresponding to embeddings\n",
    "    raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]\n",
    "    print(raw_input_state)\n",
    "    print(input_state)\n",
    "    print(raw_next_state)\n",
    "    print(next_state)\n",
    "    if index > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.95867693"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "s1 = torch.rand(size = (5, 50))\n",
    "s2 = torch.rand(size = (5, 50))\n",
    "get_cosine_sim(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gensim\n",
    "TOKENS_RAW_CUTOFF = 5\n",
    "\n",
    "def get_vectors():\n",
    "    model = gensim.models.Word2Vec.load(\"../models/custom_w2v_intersect_GoogleNews\") # (\"./models/custom_w2v\")\n",
    "    model.init_sims(replace=True) #precomputed l2 normed vectors in-place – saving the extra RAM\n",
    "    return torch.FloatTensor(w2v_model.wv.vectors)\n",
    "\n",
    "def from_pretrained(embeddings=None, freeze=True):\n",
    "    if not embeddings:\n",
    "        embeddings = get_vectors() # 2 D embeddings param\n",
    "    rows, cols = embeddings.shape\n",
    "    # A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "    embedding = torch.nn.Embedding(num_embeddings=rows, embedding_dim=cols)\n",
    "    embedding.weight = torch.nn.Parameter(embeddings)\n",
    "    # no update\n",
    "    embedding.weight.requires_grad = not freeze\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncRnn(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, num_layers,\n",
    "                 device='cpu', drop_prob=0, lstm=True, feature_norm=False,\n",
    "                 embed_size=EMBED_DIM,\n",
    "                 bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = from_pretrained()\n",
    "\n",
    "        self.memory_cell = torch.nn.GRU(input_size=embed_size,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_layers=num_layers,\n",
    "                                batch_first=True,\n",
    "                                # make dropout 0 if num_layers is 1\n",
    "                                dropout=drop_prob * (num_layers != 1),\n",
    "                                bidirectional=bidirectional)\n",
    "        self.linear = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, x, src_len):\n",
    "        x = self.dropout(self.embedding(x))\n",
    "        # packing for computation and performance\n",
    "        packed_x = torch.nn.utils.rnn.pack_padded_sequence(x, batch_first=True, lengths = src_len)\n",
    "        out, hidden = self.memory_cell(packed_x)\n",
    "        out, _ = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True) # unpack\n",
    "        out = out.transpose(1,0)\n",
    "        # initial decoder hidden is final hidden state of the forwards and\n",
    "        # backwards encoder RNNs fed through a linear layer\n",
    "        concated = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        hidden = torch.tanh(self.linear(concated))\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((hidden_size * 2) + hidden_size, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        attention = attention.masked_fill(mask == 0, -1e10) # using masking, we can force the attention to only be over non-padding elements.\n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers,\n",
    "                 device='cpu', drop_prob=0, lstm=True, feature_norm=False,\n",
    "                 embed_size=EMBED_DIM,output_size=VOCAB_SIZE,##### 5 or VOCAB_SIZE?\n",
    "                 bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "        self.embedding = from_pretrained()\n",
    "        \"\"\"\n",
    "        self.memory_cell = torch.nn.GRU(input_size=(hidden_size*2)+embed_size,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_layers=num_layers,\n",
    "                                # make dropout 0 if num_layers is 1\n",
    "                                dropout=drop_prob * (num_layers != 1),\n",
    "                                bidirectional=False)\n",
    "        \"\"\"\n",
    "        self.memory_cell = torch.nn.GRU((hidden_size * 2) + embed_size, hidden_size)\n",
    "        self.linear = nn.Linear((hidden_size * 3)+embed_size, output_size)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        ##print(input.shape) #input = [batch size]\n",
    "        ##print(hidden.shape) #hidden = [batch size, dec hid dim]\n",
    "        ##print(encoder_outputs.shape) #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        ##print(mask.shape) #mask = [batch size, src len]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        ##print(embedded.shape)\n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "        a = a.unsqueeze(1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        ##print(encoder_outputs.shape)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        ##print(weighted.shape)\n",
    "        dec_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        ##print(dec_input.shape, hidden.unsqueeze(0).shape)\n",
    "        output, hidden = self.memory_cell(dec_input, hidden.unsqueeze(0))\n",
    "\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.linear(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        ##print(prediction.shape)\n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        src = src.transpose(1,0)\n",
    "        trg = trg.transpose(1,0)\n",
    "\n",
    "        ##print(src.shape) #src = [src len, batch size]\n",
    "        ##print(src_len.shape) #src_len = [batch size]\n",
    "        ##print(trg.shape) #trg = [trg len, batch size]\n",
    "        \n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "                    \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = VOCAB_SIZE ##### 5 or VOCAB_SIZE?\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        ##print(outputs)\n",
    "        \n",
    "        src = src.transpose(1,0)\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "        src = src.transpose(1,0)\n",
    "        ##print(encoder_outputs, hidden)\n",
    "\n",
    "        input = trg[0,:]\n",
    "        ##print(input)\n",
    "        \n",
    "        mask = self.create_mask(src)\n",
    "        print(f'src = {src}'')\n",
    "        print(f'mask = {mask}')\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1) \n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "402 300\n"
     ]
    }
   ],
   "source": [
    "N_HIDDEN =2\n",
    "VOCAB_SIZE, EMBED_DIM = w2v_model.wv.vectors.shape\n",
    "print(VOCAB_SIZE, EMBED_DIM)\n",
    "SEQ_LEN = 5\n",
    "\n",
    "clip = 1\n",
    "device = 'cpu'\n",
    "enc = EncRnn(hidden_size=N_HIDDEN, num_layers=2, embed_size=EMBED_DIM)\n",
    "dec = Decoder(hidden_size=N_HIDDEN, num_layers=2, embed_size=EMBED_DIM, output_size=VOCAB_SIZE)\n",
    "model = Seq2Seq(enc, dec, 0, device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = 0\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncRnn(\n",
       "    (embedding): Embedding(402, 300)\n",
       "    (memory_cell): GRU(300, 2, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    (linear): Linear(in_features=4, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=6, out_features=2, bias=True)\n",
       "      (v): Linear(in_features=2, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(402, 300)\n",
       "    (memory_cell): GRU(304, 2)\n",
       "    (linear): Linear(in_features=306, out_features=402, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 345
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True, False,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True, False,  True,  True,  True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True, False,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True, False,  True, False, False]])\n",
      "mask = tensor([[ True, False,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True, False,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True, False,  True,  True, False]])\n",
      "mask = tensor([[ True, False,  True, False, False]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True, False,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True, False,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True, False, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True, False, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n",
      "mask = tensor([[True, True, True, True, True]])\n",
      "mask = tensor([[ True,  True,  True,  True, False]])\n",
      "mask = tensor([[ True,  True,  True, False, False]])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-346-580e03fd9717>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "model.train()\n",
    "EPOCHS = 2\n",
    "epoch_loss = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for idx, (index, vects) in enumerate(d.items()):\n",
    "            # each is N x 300\n",
    "            input_state, next_state = vects[0], vects[1]\n",
    "            # raw strings corresponding to embeddings\n",
    "            raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]\n",
    "            \n",
    "            ### add <sos> and <eos>\n",
    "            ##tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "\n",
    "            trg = next_state.unsqueeze(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_state.unsqueeze(0), torch.Tensor([SEQ_LEN]), trg)\n",
    "\n",
    "\n",
    "            trg = trg.transpose(1,0)\n",
    "            ##print(\"\\n\")\n",
    "            ##print(trg.shape) #trg = [trg len, batch size]\n",
    "            ##print(output.shape) #output = [trg len, batch size, output dim]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            ##print(trg.shape) #trg = [(trg len - 1) * batch size]\n",
    "            ##print(output.shape) #output = [(trg len - 1) * batch size, output dim]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "    print(f'\\tTrain Loss: {epoch_loss / len(d):.3f} | Train PPL: {math.exp(epoch_loss / len(d)):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(words, input_state, next_state, model, max_len = 5):\n",
    "\n",
    "    model.eval()\n",
    "    src_tensor = input_state.unsqueeze(0)\n",
    "    src_len = torch.Tensor([SEQ_LEN])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
    "\n",
    "    mask = model.create_mask(src_tensor.transpose(1,0))\n",
    "    # get first decoder input (<sos>)'s one hot\n",
    "    trg_indexes = [next_state[0]]\n",
    "    # create a array to store attetnion\n",
    "    attentions = torch.zeros(max_len, 1, len(input_state))\n",
    "    #print(attentions.shape)\n",
    "\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]])\n",
    "        #print(trg_tensor.shape)\n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "        attentions[i] = attention\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        #if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "        #    break\n",
    "        \n",
    "    trg_tokens = [words[int(ind)] for ind in trg_indexes]\n",
    "    #return trg_tokens[1:], attentions[:len(trg_tokens)-1]\n",
    "    return trg_tokens, attentions[:len(trg_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.vocabulary.sorted_vocab\n",
    "word_counts = {word: vocab_obj.count for word, vocab_obj in w2v_model.wv.vocab.items()}\n",
    "word_counts = sorted(word_counts.items(), key=lambda x:-x[1])\n",
    "words = [t[0] for t in word_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "src = ['go', 'find', 'one', '.', '.']\n",
      "trg = ['<person>', \"'s\", 'name', '.', '.']\n",
      "predicted trg = ['<person>', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['oh', 'fuck', '!', '.', '.']\n",
      "trg = ['fuck', 'you', '.', '.', '.']\n",
      "predicted trg = ['fuck', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['okay', '.', '.', '.', '.']\n",
      "trg = ['hey', ',', 'honey', '.', '.']\n",
      "predicted trg = ['hey', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['<person>', '?', '.', '.', '.']\n",
      "trg = ['yes', '.', '.', '.', '.']\n",
      "predicted trg = ['yes', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['<person>', '<person>', '?', '.', '.']\n",
      "trg = ['<person>', '<person>', '<person>', '!', '.']\n",
      "predicted trg = ['<person>', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['<person>', '!', '...', '<person>', '!']\n",
      "trg = ['<person>', '<person>', '?', '.', '.']\n",
      "predicted trg = ['<person>', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['okay', '.', 'great', '!', '.']\n",
      "trg = ['okay', '.', '.', '.', '.']\n",
      "predicted trg = ['okay', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['<person>', '!', '!', '.', '.']\n",
      "trg = ['where', '?', '!', '.', '.']\n",
      "predicted trg = ['where', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['you', 'were', 'late', '.', '.']\n",
      "trg = ['i', \"'m\", 'really', 'sorry', '.']\n",
      "predicted trg = ['i', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['see', 'ya', '<date>', '.', '.']\n",
      "trg = ['you', 'were', 'late', '.', '.']\n",
      "predicted trg = ['you', '?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "src = ['okay', ',', 'be', 'careful', '.']\n",
      "trg = ['okay', ',', '<person>', '.', '.']\n",
      "predicted trg = ['okay', '?', '?', '?', '?', '?']\n"
     ]
    }
   ],
   "source": [
    "src = None\n",
    "trg = None\n",
    "for idx, (index, vects) in enumerate(d.items()):\n",
    "        # each is N x 300\n",
    "        input_state, next_state = vects[0], vects[1]\n",
    "        # raw strings corresponding to embeddings\n",
    "        raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]\n",
    "        #print(input_state, next_state)\n",
    "\n",
    "        src = input_state\n",
    "        trg = next_state\n",
    "\n",
    "        print(\"src = {}\".format([words[int(ind)] for ind in src.numpy()]))\n",
    "        print(\"trg = {}\".format([words[int(ind)] for ind in trg.numpy()]))\n",
    "\n",
    "        translation, attention = translate_sentence(words, src,trg, model)\n",
    "\n",
    "        print(f'predicted trg = {translation}') \n",
    "        #display_attention([words[int(ind)] for ind in src.numpy()], translation, attention)\n",
    "\n",
    "        if idx >= 10:\n",
    "            break\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels(['']+sentence,rotation=45)\n",
    "    ax.set_yticklabels(['']+translation)\n",
    "    #ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "    #                   rotation=45)\n",
    "    #ax.set_yticklabels(['']+translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"601.19485pt\" version=\"1.1\" viewBox=\"0 0 596.720312 601.19485\" width=\"596.720312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 601.19485 \r\nL 596.720312 601.19485 \r\nL 596.720312 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 45.920313 590.49485 \r\nL 589.520312 590.49485 \r\nL 589.520312 46.89485 \r\nL 45.920313 46.89485 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p846570ca5b)\">\r\n    <image height=\"544\" id=\"imageb310d023bd\" transform=\"scale(1 -1)translate(0 -544)\" width=\"544\" x=\"45.920313\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-46.49485\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m3d214f9954\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"100.280312\" xlink:href=\"#m3d214f9954\" y=\"590.49485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 -3.5 \r\n\" id=\"m5ecce57e7b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"100.280312\" xlink:href=\"#m5ecce57e7b\" y=\"46.89485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- oh -->\r\n      <defs>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      </defs>\r\n      <g transform=\"translate(96.601148 37.689008)rotate(-45)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-111\"/>\r\n       <use x=\"61.181641\" xlink:href=\"#DejaVuSans-104\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.000312\" xlink:href=\"#m3d214f9954\" y=\"590.49485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.000312\" xlink:href=\"#m5ecce57e7b\" y=\"46.89485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- fuck -->\r\n      <defs>\r\n       <path d=\"M 37.109375 75.984375 \r\nL 37.109375 68.5 \r\nL 28.515625 68.5 \r\nQ 23.6875 68.5 21.796875 66.546875 \r\nQ 19.921875 64.59375 19.921875 59.515625 \r\nL 19.921875 54.6875 \r\nL 34.71875 54.6875 \r\nL 34.71875 47.703125 \r\nL 19.921875 47.703125 \r\nL 19.921875 0 \r\nL 10.890625 0 \r\nL 10.890625 47.703125 \r\nL 2.296875 47.703125 \r\nL 2.296875 54.6875 \r\nL 10.890625 54.6875 \r\nL 10.890625 58.5 \r\nQ 10.890625 67.625 15.140625 71.796875 \r\nQ 19.390625 75.984375 28.609375 75.984375 \r\nz\r\n\" id=\"DejaVuSans-102\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 31.109375 \r\nL 44.921875 54.6875 \r\nL 56.390625 54.6875 \r\nL 27.390625 29.109375 \r\nL 57.625 0 \r\nL 45.90625 0 \r\nL 18.109375 26.703125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nz\r\n\" id=\"DejaVuSans-107\"/>\r\n      </defs>\r\n      <g transform=\"translate(200.712248 37.689008)rotate(-45)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-102\"/>\r\n       <use x=\"35.205078\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"98.583984\" xlink:href=\"#DejaVuSans-99\"/>\r\n       <use x=\"153.564453\" xlink:href=\"#DejaVuSans-107\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"317.720312\" xlink:href=\"#m3d214f9954\" y=\"590.49485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"317.720312\" xlink:href=\"#m5ecce57e7b\" y=\"46.89485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- ! -->\r\n      <defs>\r\n       <path d=\"M 15.09375 12.40625 \r\nL 25 12.40625 \r\nL 25 0 \r\nL 15.09375 0 \r\nz\r\nM 15.09375 72.90625 \r\nL 25 72.90625 \r\nL 25 40.921875 \r\nL 24.03125 23.484375 \r\nL 16.109375 23.484375 \r\nL 15.09375 40.921875 \r\nz\r\n\" id=\"DejaVuSans-33\"/>\r\n      </defs>\r\n      <g transform=\"translate(318.520779 37.689008)rotate(-45)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-33\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"426.440312\" xlink:href=\"#m3d214f9954\" y=\"590.49485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"426.440312\" xlink:href=\"#m5ecce57e7b\" y=\"46.89485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- . -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(427.681616 37.689008)rotate(-45)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-46\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"535.160312\" xlink:href=\"#m3d214f9954\" y=\"590.49485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"535.160312\" xlink:href=\"#m5ecce57e7b\" y=\"46.89485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- . -->\r\n      <g transform=\"translate(536.401616 37.689008)rotate(-45)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-46\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_11\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m88fe814319\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.920313\" xlink:href=\"#m88fe814319\" y=\"101.25485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- fuck -->\r\n      <g transform=\"translate(7.2 106.953678)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-102\"/>\r\n       <use x=\"35.205078\" xlink:href=\"#DejaVuSans-117\"/>\r\n       <use x=\"98.583984\" xlink:href=\"#DejaVuSans-99\"/>\r\n       <use x=\"153.564453\" xlink:href=\"#DejaVuSans-107\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.920313\" xlink:href=\"#m88fe814319\" y=\"209.97485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- . -->\r\n      <g transform=\"translate(34.153125 215.673678)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-46\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.920313\" xlink:href=\"#m88fe814319\" y=\"318.69485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- . -->\r\n      <g transform=\"translate(34.153125 324.393678)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-46\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.920313\" xlink:href=\"#m88fe814319\" y=\"427.41485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- . -->\r\n      <g transform=\"translate(34.153125 433.113678)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-46\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.920313\" xlink:href=\"#m88fe814319\" y=\"536.13485\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- . -->\r\n      <g transform=\"translate(34.153125 541.833678)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#DejaVuSans-46\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 45.920313 590.49485 \r\nL 45.920313 46.89485 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 589.520312 590.49485 \r\nL 589.520312 46.89485 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 45.920313 590.49485 \r\nL 589.520312 590.49485 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 45.920313 46.89485 \r\nL 589.520312 46.89485 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p846570ca5b\">\r\n   <rect height=\"543.6\" width=\"543.6\" x=\"45.920313\" y=\"46.89485\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "display_attention([words[int(ind)] for ind in src.numpy()], translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for idx, (index, vects) in enumerate(d.items()):\n",
    "        # each is N x 300\n",
    "        input_state, next_state = vects[0], vects[1]\n",
    "        # raw strings corresponding to embeddings\n",
    "        raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]\n",
    "        \n",
    "        mu = actor(input_state.unsqueeze(0))\n",
    "        \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src, src_len = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_len, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src, src_len = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_iterator' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b6ffe8a7b674>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#start_time = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_iterator' is not defined"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    #start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #end_time = time.time()\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 5])\ntorch.Size([5, 1, 4]) torch.Size([4, 1, 2])\ntorch.Size([5, 1, 4]) torch.Size([1, 2])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'detach'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1df496d31032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# ACTOR FORMAT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlogstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "actor = EncRnn(hidden_size=2, num_layers=2, embed_size=300)\n",
    "actor_criterion = torch.nn.MSELoss()\n",
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr=0.001)\n",
    "#print(actor)\n",
    "\n",
    "running_loss=0.0\n",
    "for idx, (index, vects) in enumerate(d.items()):\n",
    "    # each is N x 300\n",
    "    input_state, next_state = vects[0], vects[1]\n",
    "    # raw strings corresponding to embeddings\n",
    "    raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]\n",
    "    \n",
    "    mu = actor(input_state.unsqueeze(0))\n",
    "    \n",
    "    # ACTOR FORMAT\n",
    "    logstd = torch.zeros_like(mu.detach())\n",
    "    std = 0.05*torch.exp(logstd)\n",
    "    action = get_action(mu.detach(), std)[0]\n",
    "    \n",
    "    print(raw_input_state,\" || \",get_raw_action(action))\n",
    "    # non greedy and greedy sim\n",
    "    print(raw_next_state, 'non-greedy:', get_cosine_sim(next_state, action), 'greedy:', get_cosine_sim(next_state, action, type='greedy'))\n",
    "    print(\"\\n\")\n",
    "    # CONVENTIONAL TRAINING\n",
    "    # zero the parameter gradients\n",
    "    actor_optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    if idx == 0:\n",
    "        print(mu.shape, next_state.shape)\n",
    "    loss = actor_criterion(mu.squeeze(0), next_state)\n",
    "    loss.backward()\n",
    "    actor_optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    if idx > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'VOCAB_SIZE' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c4cb07b286a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mEncRnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     def __init__(self, hidden_size, num_layers,\n\u001b[0;32m      4\u001b[0m                  \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c4cb07b286a4>\u001b[0m in \u001b[0;36mEncRnn\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     def __init__(self, hidden_size, num_layers,\n\u001b[0;32m      4\u001b[0m                  \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                  \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                  bidirectional=False):\n\u001b[0;32m      7\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VOCAB_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "class EncRnn(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, num_layers,\n",
    "                 device='cpu', drop_prob=0, lstm=True, feature_norm=False,\n",
    "                 input_size=1, output_size=VOCAB_SIZE,\n",
    "                 bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embedding = from_pretrained()\n",
    "\n",
    "        self.memory_cell = torch.nn.GRU(input_size=input_size,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_layers=num_layers,\n",
    "                                batch_first=True,\n",
    "                                # make dropout 0 if num_layers is 1\n",
    "                                dropout=drop_prob * (num_layers != 1),\n",
    "                                bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            self.linear = nn.Linear(hidden_size * 2, output_size)\n",
    "        else:\n",
    "            self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        if self.bidirectional:\n",
    "            h = torch.autograd.Variable(torch.zeros(1, batch_size, self.hidden_size * 2))\n",
    "        else:\n",
    "            h = torch.autograd.Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "\n",
    "        if self.device == 'cuda':\n",
    "            return h.cuda()\n",
    "        else:\n",
    "            return h\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.embedding(x))\n",
    "        print(x.shape)\n",
    "        x = x.view(1, -1, EMBED_DIM)\n",
    "        ## packing for computation and performance\n",
    "        #packed_x = torch.nn.utils.rnn.pack_padded_sequence(x, batch_first=True, lengths = [x.shape[1]]*x.shape[0])\n",
    "        out, hidden = self.memory_cell(x) #(packed_x)\n",
    "        #out, _ = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True) # unpack\n",
    "        #out = out.transpose(1,0)\n",
    "        print(out.shape)\n",
    "        if self.bidirectional:\n",
    "            out = self.linear(out.view(-1, self.hidden_size * 2)) # batch_size x vocab_size\n",
    "        else:\n",
    "            out = self.linear(out.view(-1, self.hidden_size))\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out, hidden\n",
    "\n",
    "    def batchNLLLoss(self, x, target):\n",
    "        \"\"\"\n",
    "        Returns the NLL Loss for predicting target sequence.\n",
    "        Inputs: inp, target\n",
    "            - x: batch_size x seq_len\n",
    "            - target: batch_size x seq_len\n",
    "            x should be target with <s> (start letter) prepended\n",
    "        \"\"\"\n",
    "\n",
    "        loss_fn = nn.NLLLoss()\n",
    "        batch_size, seq_len = x.size()\n",
    "        x = x.permute(1, 0)           # seq_len x batch_size\n",
    "        target = target.permute(1, 0)     # seq_len x batch_size\n",
    "        h = self.init_hidden(batch_size)\n",
    "\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            out, h = self.forward(x[i], h)\n",
    "            loss += loss_fn(out, target[i])\n",
    "\n",
    "        return loss     # per batc\n",
    "\n",
    "    def batchPGLoss(self, x, target, reward):\n",
    "        \"\"\"\n",
    "        Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).\n",
    "        Inspired by the example in http://karpathy.github.io/2016/05/31/rl/\n",
    "        Inputs: x, target\n",
    "            - x: batch_size x seq_len\n",
    "            - target: batch_size x seq_len\n",
    "            - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding\n",
    "                      sentence)\n",
    "            inp should be target with <s> (start letter) prepended\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len = x.size()\n",
    "        x = x.permute(1, 0)          # seq_len x batch_size\n",
    "        target = target.permute(1, 0)    # seq_len x batch_size\n",
    "        h = self.init_hidden(batch_size)\n",
    "\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            out, h = self.forward(x[i], h)\n",
    "            # TODO: should h be detached from graph (.detach())?\n",
    "            for j in range(batch_size):\n",
    "                loss += -out[j][target.data[i][j]]*reward[j]     # log(P(y_t|Y_1:Y_{t-1})) * Q\n",
    "\n",
    "        return loss/batch_size\n",
    "\n",
    "\n",
    "actor = EncRnn(hidden_size=2, num_layers=2, input_size=300)#, output_size=50) #Seq2Seq(hidden_size=2, num_layers=2, input_size=50, output_size=50)\n",
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr=0.001)\n",
    "#print(actor)\n",
    "\n",
    "running_loss=0.0\n",
    "for idx, (index, vects) in enumerate(d.items()):\n",
    "    # each is N x 300\n",
    "    input_state, next_state = vects[0], vects[1]\n",
    "    # raw strings corresponding to embeddings\n",
    "    raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]\n",
    "    \n",
    "    for i in range(len(input_state)-1):\n",
    "        tok = input_state[i]\n",
    "        target = input_state[i+1]\n",
    "        enc_in = tok.unsqueeze(0)\n",
    "        enc_out, hidden = actor(enc_in)\n",
    "        print(enc_out.shape, hidden.shape)\n",
    "\n",
    "        actor_optimizer.zero_grad()\n",
    "        print(target.unsqueeze(0).shape)\n",
    "        loss = actor.batchNLLLoss(enc_in, target.unsqueeze(0))\n",
    "        loss.backward()\n",
    "        actor_optimizer.step()\n",
    "\n",
    "    \"\"\"\n",
    "    # ACTOR FORMAT\n",
    "    logstd = torch.zeros_like(mu.detach())\n",
    "    std = 0.05*torch.exp(logstd)\n",
    "    action = get_action(mu.detach(), std)[0]\n",
    "    \n",
    "    print(raw_input_state,\" || \",get_raw_action(action))\n",
    "    # non greedy and greedy sim\n",
    "    print(raw_next_state, 'non-greedy:', get_cosine_sim(next_state, action), 'greedy:', get_cosine_sim(next_state, action, type='greedy'))\n",
    "    print(\"\\n\")\n",
    "    \"\"\"\n",
    "    # CONVENTIONAL TRAINING\n",
    "    # zero the parameter gradients\n",
    "    actor_optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    print(next_state.unsqueeze(0).shape)\n",
    "    loss = actor.batchNLLLoss(mu, next_state.unsqueeze(0))\n",
    "    loss.backward()\n",
    "    actor_optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    print(running_loss)\n",
    "\n",
    "    if idx > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('./spacy-blank-GoogleNews/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token_vector in action:\n",
    "    v = token_vector.numpy()\n",
    "    nlp.similarity(v, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def cosine_similarity_numba(u:np.ndarray, v:np.ndarray):\n",
    "    assert(u.shape[0] == v.shape[0])\n",
    "    uv = 0\n",
    "    uu = 0\n",
    "    vv = 0\n",
    "    for i in range(u.shape[0]):\n",
    "        uv += u[i]*v[i]\n",
    "        uu += u[i]*u[i]\n",
    "        vv += v[i]*v[i]\n",
    "    cos_theta = 1\n",
    "    if uu != 0 and vv != 0:\n",
    "        cos_theta = uv/np.sqrt(uu*vv)\n",
    "    return cos_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "def most_similar(word, topn=5):\n",
    "  word = nlp.vocab[str(word)]\n",
    "  queries = [\n",
    "      w for w in word.vocab \n",
    "      if w.is_lower == word.is_lower and w.prob >= -15 and np.count_nonzero(w.vector)\n",
    "  ]\n",
    "\n",
    "  by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "  return [(w.lower_,w.similarity(word)) for w in by_similarity[:topn+1] if w.lower_ != word.lower_]\n",
    "\n",
    "most_similar(\"dog\", topn=3)"
   ]
  }
 ]
}