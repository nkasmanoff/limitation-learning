{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main.py file for GAIL implementation on dialog datasets.\n",
    "\n",
    "Uses command line arguments to maximize flexibility, and run many options in parallel\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys \n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from models.actor import Actor\n",
    "from models.critic import Critic\n",
    "from models.discriminator import Discriminator\n",
    "from GAIL import *\n",
    "\n",
    "from dialog_environment import DialogEnvironment\n",
    "\n",
    "device='cuda' # for now\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Limitation Learning')\n",
    "\n",
    "parser.add_argument('--load_model', \n",
    "                    type=str, default=None, \n",
    "                    help='path to load the saved model')\n",
    "\n",
    "parser.add_argument('--gamma', \n",
    "                    type=float, default=0.99, \n",
    "                    help='discounted factor (default: 0.99)')\n",
    "\n",
    "parser.add_argument('--lamda', \n",
    "                    type=float, default=0.98, \n",
    "                    help='GAE hyper-parameter (default: 0.98)')\n",
    "\n",
    "\n",
    "parser.add_argument('--learning_rate', \n",
    "                    type=float, default=3e-4, \n",
    "                    help='learning rate of models (default: 3e-4)')\n",
    "\n",
    "parser.add_argument('--l2_rate', \n",
    "                    type=float, default=1e-3, \n",
    "                    help='l2 regularizer coefficient (default: 1e-3)')\n",
    "\n",
    "parser.add_argument('--clip_param', \n",
    "                    type=float, default=0.2, \n",
    "                    help='clipping parameter for PPO (default: 0.2)')\n",
    "\n",
    "parser.add_argument('--discrim_update_num', \n",
    "                    type=int, default=2, \n",
    "                    help='update number of discriminator (default: 2)')\n",
    "\n",
    "parser.add_argument('--actor_critic_update_num', \n",
    "                    type=int, default=10, \n",
    "                    help='update number of actor-critic (default: 10)')\n",
    "\n",
    "parser.add_argument('--total_sample_size', \n",
    "                    type=int, default=2048, \n",
    "                    help='total sample size to collect before PPO update (default: 2048)')\n",
    "\n",
    "parser.add_argument('--batch_size', \n",
    "                    type=int, default=128, \n",
    "                    help='batch size to update (default: 128)')\n",
    "\n",
    "parser.add_argument('--suspend_accu_exp', \n",
    "                    type=float, default=None,\n",
    "                    help='accuracy for suspending discriminator about expert data (default: None)')\n",
    "\n",
    "parser.add_argument('--suspend_accu_gen', \n",
    "                    type=float, default=None,\n",
    "                    help='accuracy for suspending discriminator about generated data (default: None)')\n",
    "\n",
    "parser.add_argument('--max_iter_num', \n",
    "                    type=int, default=4096,\n",
    "                    help='maximal number of main iterations (default: 4000)')\n",
    "\n",
    "parser.add_argument('--seed', \n",
    "                    type=int, default=42,\n",
    "                    help='random seed (default: 500)')\n",
    "\n",
    "parser.add_argument('--logdir', \n",
    "                    type=str, default='logs/EXPERIMENTNAME',\n",
    "                    help='tensorboardx logs directory (default: logs/EXPERIMENTNAME)')\n",
    "\n",
    "parser.add_argument('--hidden_size', \n",
    "                    type=int, default=128,\n",
    "                    help='New sequence length of the representation produced by the encoder/decoder RNNs. (default: 1024)')\n",
    "parser.add_argument('--num_layers', \n",
    "                    type=int, default=2,\n",
    "                    help='Number of layers in the respective RNNs (default: 2)')\n",
    "\n",
    "parser.add_argument('--seq_len', \n",
    "                    type=int, default=10,\n",
    "                    help='length of input and response sequences (default: 60, which is also max)')\n",
    "parser.add_argument('--input_size', \n",
    "                    type=int, default=300,\n",
    "                    help='DO NOT CHANGE UNLESS NEW EMBEDDINGS ARE MADE. Dimensionality of embeddings (default: 300)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from argparse import Namespace\n",
    "args = Namespace(load_model=None,\n",
    "                render=False,\n",
    "                gamma=.99,\n",
    "                lamda=.98,\n",
    "                learning_rate=1e-4,\n",
    "                l2_rate=1e-3,\n",
    "                clip_param=.2,\n",
    "                discrim_update_num=1,\n",
    "                actor_critic_update_num=100,\n",
    "                total_sample_size=100,\n",
    "                batch_size=100,\n",
    "                suspend_accu_exp=None,# won't stop\n",
    "                suspend_accu_gen=None,\n",
    "                max_iter_num=4000,\n",
    "                seed=500,\n",
    "                logdir='logs/noah7',\n",
    "                 hidden_size=1,\n",
    "                 num_layers=1,\n",
    "                 seq_len=10,\n",
    "                 input_size=300\n",
    "                )\n",
    "env = DialogEnvironment()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "#TODO\n",
    "actor = Actor(hidden_size=args.hidden_size,num_layers=args.num_layers,device='cuda',input_size=args.input_size,output_size=args.input_size)\n",
    "critic = Critic(hidden_size=args.hidden_size,num_layers=args.num_layers,input_size=args.input_size,seq_len=args.seq_len)\n",
    "discrim = Discriminator(hidden_size=args.hidden_size,num_layers=args.hidden_size,input_size=args.input_size,seq_len=args.seq_len)\n",
    "\n",
    "actor.to(device), critic.to(device), discrim.to(device)\n",
    "\n",
    "actor_optim = optim.Adam(actor.parameters(), lr=args.learning_rate)\n",
    "critic_optim = optim.Adam(critic.parameters(), lr=args.learning_rate, \n",
    "                          weight_decay=args.l2_rate) \n",
    "discrim_optim = optim.Adam(discrim.parameters(), lr=args.learning_rate)\n",
    "\n",
    "# load demonstrations\n",
    "\n",
    "writer = SummaryWriter(args.logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, expert_action, raw_state, raw_expert_action = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAIL import get_cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cosine_sim(s1=expert_action,s2=action.squeeze(),seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "i = 0\n",
    "while i < 100:\n",
    "\n",
    "    state, expert_action, raw_state, raw_expert_action = env.reset()\n",
    "    i +=1\n",
    "    states.append(state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0][0:1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0][0:1,:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(states[0][0:1,:].flatten().numpy(),bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([i.item()**2 for i in emb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is L2 Normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(mu, std):\n",
    "    \"\"\"\n",
    "    L2 norm is equal to 1 across the embedding dimension for all tokens.\n",
    "    \"\"\"\n",
    "    action = torch.normal(mu, std)\n",
    "    \n",
    "    norm = action.norm(p=2, dim=2, keepdim=True)\n",
    "    action = action.div(norm.expand_as(action))\n",
    "    action = action.detach().cpu().numpy()\n",
    "\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, std = actor(torch.randn(1,5,300).to(device))\n",
    "action = get_action(mu,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([i.item()**2 for i in action[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(action[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action[0][1].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1.5130e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_action[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, expert_action, raw_state, raw_expert_action = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.load_model is not None: #TODO\n",
    "    saved_ckpt_path = os.path.join(os.getcwd(), 'save_model', str(args.load_model))\n",
    "    ckpt = torch.load(saved_ckpt_path)\n",
    "\n",
    "    actor.load_state_dict(ckpt['actor'])\n",
    "    critic.load_state_dict(ckpt['critic'])\n",
    "    discrim.load_state_dict(ckpt['discrim'])\n",
    "\n",
    "\n",
    "\n",
    "episodes = 0\n",
    "train_discrim_flag = True\n",
    "\n",
    "for iter in range(args.max_iter_num):\n",
    "    actor.eval(), critic.eval()\n",
    "    memory = deque()\n",
    "\n",
    "    steps = 0\n",
    "    scores = []\n",
    "    similarity_scores = []\n",
    "    while steps < args.total_sample_size: \n",
    "        state, expert_action, raw_state, raw_expert_action = env.reset()\n",
    "        score = 0\n",
    "        similarity_score = 0\n",
    "        state = state[:args.seq_len,:]\n",
    "        expert_action = expert_action[:args.seq_len,:]\n",
    "        state = state.to(device)\n",
    "        expert_action = expert_action.to(device)\n",
    "        for _ in range(10000): \n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            mu, std = actor(state.resize(1,args.seq_len,args.input_size)) #TODO: gotta be a better way to resize. \n",
    "            action = get_action(mu.cpu(), std.cpu())[0]\n",
    "            done= env.step(action)\n",
    "            irl_reward = get_reward(discrim, state, action, args)\n",
    "            if done:\n",
    "                mask = 0\n",
    "            else:\n",
    "                mask = 1\n",
    "\n",
    "\n",
    "            memory.append([state, torch.from_numpy(action).to(device), irl_reward, mask,expert_action])\n",
    "            score += irl_reward\n",
    "       #     similarity_score += get_cosine_sim(action,expert_action)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        episodes += 1\n",
    "        scores.append(score)\n",
    "       # similarity_scores.append(similarity_score)\n",
    "\n",
    "    score_avg = np.mean(scores)\n",
    "  #  similarity_score_avg = np.mean(similarity_scores)\n",
    "    print('{}:: {} episode score is {:.2f}'.format(iter, episodes, score_avg))\n",
    "   # print('{}:: {} episode similarity score is {:.2f}'.format(iter, episodes, similarity_score_avg))\n",
    "\n",
    "    actor.train(), critic.train(), discrim.train()\n",
    "    if train_discrim_flag:\n",
    "        expert_acc, learner_acc = train_discrim(discrim, memory, discrim_optim, args) \n",
    "        print(\"Expert: %.2f%% | Learner: %.2f%%\" % (expert_acc * 100, learner_acc * 100))\n",
    "        writer.add_scalar('log/expert_acc', float(expert_acc), iter) #logg\n",
    "        writer.add_scalar('log/learner_acc', float(learner_acc), iter) #logg\n",
    "        writer.add_scalar('log/avg_acc', float(learner_acc + expert_acc)/2, iter) #logg\n",
    "        if args.suspend_accu_exp is not None: #only if not None do we check.\n",
    "            if expert_acc > args.suspend_accu_exp and learner_acc > args.suspend_accu_gen:\n",
    "                train_discrim_flag = False\n",
    "\n",
    "    train_actor_critic(actor, critic, memory, actor_optim, critic_optim, args)\n",
    "    writer.add_scalar('log/score', float(score_avg), iter)\n",
    " #   writer.add_scalar('log/similarity_score', float(similarity_score_avg), iter)\n",
    "    writer.add_text('log/raw_state', raw_state[0],iter)\n",
    "    raw_action = get_raw_action(action) #TODO\n",
    "    writer.add_text('log/raw_action', raw_action,iter)\n",
    "    writer.add_text('log/raw_expert_action', raw_expert_action,iter)\n",
    "\n",
    "    if iter % 100:\n",
    "        score_avg = int(score_avg)\n",
    "\n",
    "\n",
    "        model_path = os.path.join(os.getcwd(),'save_model')\n",
    "        if not os.path.isdir(model_path):\n",
    "            os.makedirs(model_path)\n",
    "\n",
    "            ckpt_path = os.path.join(model_path, 'ckpt_'+ str(score_avg)+'.pth.tar')\n",
    "\n",
    "            save_checkpoint({\n",
    "                'actor': actor.state_dict(),\n",
    "                'critic': critic.state_dict(),\n",
    "                'discrim': discrim.state_dict(),\n",
    "                'args': args,\n",
    "                'score': score_avg,\n",
    "            }, filename=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
