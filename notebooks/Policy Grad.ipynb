{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.utils import get_model\n",
    "from models.config import TOKENS_RAW_CUTOFF\n",
    "from models.seq2seqattn import init_weights, EncRnn, DecRnn, Seq2SeqAttn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = get_model()\n",
    "# w2ind from w2v\n",
    "w2ind = {token: token_index for token_index, token in enumerate(w2v_model.wv.index2word)} \n",
    "# sorted vocab words\n",
    "assert w2v_model.vocabulary.sorted_vocab == True\n",
    "word_counts = {word: vocab_obj.count for word, vocab_obj in w2v_model.wv.vocab.items()}\n",
    "word_counts = sorted(word_counts.items(), key=lambda x:-x[1])\n",
    "words = [t[0] for t in word_counts]\n",
    "# sentence marker token inds\n",
    "sos_ind = w2ind['<sos>']\n",
    "eos_ind = w2ind['<eos>']\n",
    "# adjusted sequence length\n",
    "SEQ_LEN = 5 + 2 # sos, eos tokens\n",
    "# padding token for now\n",
    "TRG_PAD_IDX = w2ind[\".\"] # this is 0\n",
    "# vocab, embed dims\n",
    "VOCAB_SIZE, EMBED_DIM = w2v_model.wv.vectors.shape\n",
    "VOCAB_SIZE, EMBED_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "enc = EncRnn(hidden_size=64, num_layers=2, embed_size=EMBED_DIM)\n",
    "dec = DecRnn(hidden_size=64, num_layers=2, embed_size=EMBED_DIM, output_size=VOCAB_SIZE)\n",
    "model = Seq2SeqAttn(enc, dec, TRG_PAD_IDX, VOCAB_SIZE, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\n",
    "    '/scratch/nsk367/deepRL/limitation-learning/src/pretrained_generators/model-epoch10.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.load('../dat/processed/padded_vectorized_states_v3.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(words, input_state, next_state, model, eos_ind, max_len, device):\n",
    "    \n",
    "    model.eval()\n",
    "    src_tensor = input_state.unsqueeze(0).to(device)\n",
    "    src_len = torch.Tensor([int(max_len)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
    "\n",
    "    mask = model.create_mask(src_tensor.transpose(1,0)).to(device)\n",
    "    # get first decoder input (<sos>)'s one hot\n",
    "    trg_indexes = [next_state[0]]\n",
    "    # create a array to store attetnion\n",
    "    attentions = torch.zeros(max_len, 1, len(input_state))\n",
    "    #print(attentions.shape)\n",
    "\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        #print(trg_tensor.shape)\n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "        #print(F.softmax(output))\n",
    "        attentions[i] = attention\n",
    "        pred_token = output.argmax(1).item()\n",
    "        if pred_token == eos_ind: # end of sentence.\n",
    "            break\n",
    "        trg_indexes.append(pred_token)\n",
    "        \n",
    "    trg_tokens = [words[int(ind)] for ind in trg_indexes]\n",
    "    #  remove <sos>\n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_probs(model, input_state, sos_ind, eos_ind, SEQ_LEN, device):\n",
    "    \"\"\"\n",
    "    Given an input sequence and policy, produce a distribution over tokens the predicted token for each step in the sequence. \n",
    "    \"\"\"\n",
    "    src_tensor = input_state.unsqueeze(0).to(device)\n",
    "    src_len = torch.Tensor([int(SEQ_LEN)])\n",
    "    encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n",
    "    print('encoutshape',encoder_outputs.shape)\n",
    "    mask = model.create_mask(src_tensor.transpose(1,0)).to(device)\n",
    "    trg_indexes = [sos_ind]\n",
    "    attentions = torch.zeros(SEQ_LEN, 1, len(input_state))\n",
    "    outputs = []\n",
    "    for i in range(SEQ_LEN):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
    "        attentions[i] = attention\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "       # print(pred_token)\n",
    "        if pred_token == eos_ind: # end of sentence.\n",
    "        \n",
    "            break\n",
    "        outputs.append(output)\n",
    "        \n",
    "  #  trg_tokens = [words[int(ind)] for ind in trg_indexes]\n",
    "    #  remove <sos>\n",
    "    return F.softmax(torch.stack(outputs)).to(device)\n",
    "    #return torch.stack(outputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for toke in range(output_dist.shape[0]):\n",
    "    m = Categorical(output_dist[toke])\n",
    "    action = m.sample()\n",
    "    action_log_prob = m.log_prob(action)# * reward\n",
    "    print(action_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = -action_log_prob * irl_reward\n",
    "\n",
    "# irl_reward = what discriminator says\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator(action,state) -> # between 0 and 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(action_probs):\n",
    "\n",
    "for toke in range(output_dist.shape[0]):\n",
    "    m = Categorical(output_dist[toke])\n",
    "    action = m.sample()\n",
    "    action_log_prob = m.log_prob(action)# * reward\n",
    "    print(action_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = []\n",
    "action_log_probs = []\n",
    "for i in action_probs:\n",
    "    m = Categorical(i)\n",
    "    action_ = m.sample()\n",
    "    action_log_prob = m.log_prob(action_)# * reward\n",
    "    action.append(action_.item())\n",
    "    action_log_probs.append(action_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_loss = torch.stack(action_log_probs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            policy_loss = -log_probs[batch_index] * rewards[batch_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAIL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop... \n",
    "# iterate through episodes\n",
    "for idx, (index, vects) in enumerate(d.items()):\n",
    "        input_state, expert_action = vects\n",
    "\n",
    "        input_state = torch.cat((torch.LongTensor([sos_ind]), \n",
    "                                 input_state,\n",
    "                                 torch.LongTensor([eos_ind])), \n",
    "                                 dim=0).to(device)\n",
    "        expert_action = torch.cat((torch.LongTensor([sos_ind]), \n",
    "                                expert_action, \n",
    "                                torch.LongTensor([eos_ind])), \n",
    "                               dim=0).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        action_probs =  get_action_probs(model, input_state, sos_ind, eos_ind, SEQ_LEN, device)\n",
    "        action = get_action(action_probs)\n",
    "        break\n",
    "        # get action from this using torch distributions! \n",
    "        \n",
    "        state_tokens = [words[int(ind)] for ind in input_state.cpu().detach().numpy()][1:-1]\n",
    "        #expert_act = [words[int(ind)] for ind in next_state.cpu().detach().numpy()][1:-1]\n",
    "        print(state_tokens,'\\n',target_tokens)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = input_state.unsqueeze(0).to(device)\n",
    "expert_action = expert_action.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,model,SEQ_LEN):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.state_encoder = model.encoder\n",
    "        self.action_encoder = model.encoder\n",
    "        \n",
    "        self.fc1 = nn.Linear(1280,512)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.fc3 = nn.Linear(512,1)\n",
    "        self.src_len = torch.Tensor([int(SEQ_LEN)])\n",
    "    def forward(self,x1,x2):\n",
    "        state_z, _ = self.state_encoder(x1, self.src_len)\n",
    "        action_z, _ = self.action_encoder(x2, self.src_len)\n",
    "\n",
    "        state_action = torch.cat([state_z.flatten().unsqueeze(0), action_z.flatten().unsqueeze(0)],dim=1)\n",
    "        \n",
    "        state_action = torch.relu(self.fc1(state_action))\n",
    "        state_action = torch.relu(self.fc2(state_action))\n",
    "        state_action = torch.sigmoid(self.fc3(state_action))\n",
    "\n",
    "        return state_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim = Discriminator(model,5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = discrim(state,expert_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = torch.Tensor(action).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action.un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = discrim(state,action.unsqueeze(0).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
