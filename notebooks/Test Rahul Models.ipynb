{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Rahul's Recurrent models with current code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialog_environment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DialogEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "OUTPUT_SIZE = 300 ## can be changed for integration with mlp or whatever else\n",
    "\n",
    "def subsample(data, target, n=15):\n",
    "    return [x[::n] for x in data], [y[::n] for y in target]\n",
    "\n",
    "\n",
    "class DialogData(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, state_vects, subsample_n=None):\n",
    "\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        for convo_ind, vects in state_vects.items():\n",
    "            input_state, next_state = vects[0], vects[1]\n",
    "            # can add raw state here? idk\n",
    "            data.append(input_state)\n",
    "            targets.append(next_state)\n",
    "\n",
    "        assert len(data) == len(targets)\n",
    "\n",
    "        if subsample_n:\n",
    "            data, targets = subsample(data, targets, subsample_n)\n",
    "\n",
    "        self.data = torch.stack(data)\n",
    "        self.targets = torch.stack(targets)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, num_layers,\n",
    "                 device='cpu', drop_prob=0, lstm=True, feature_norm=False,\n",
    "                 input_size=34):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        if lstm:\n",
    "            memory_cell = nn.LSTM\n",
    "        else:\n",
    "            memory_cell = nn.GRU\n",
    "\n",
    "        self.memory_cell = memory_cell(input_size,\n",
    "                                       hidden_size,\n",
    "                                       num_layers,\n",
    "                                       batch_first=True,\n",
    "                                       # make dropout 0 if num_layers is 1\n",
    "                                       dropout=drop_prob * (num_layers != 1),\n",
    "                                       bidirectional=False)\n",
    "\n",
    "        if feature_norm:\n",
    "            self.norm = nn.InstanceNorm1d(num_features=input_size)\n",
    "        else:\n",
    "            self.norm = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transpose to have features as channels\n",
    "        x = x.transpose(1, 2)\n",
    "        # run through feature norm\n",
    "        x = self.norm(x)\n",
    "        # transpose back\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        out, _ = self.memory_cell(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, num_layers,\n",
    "                 device='cpu', drop_prob=0, lstm=True, feature_norm=False):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        if lstm:\n",
    "            memory_cell = nn.LSTM\n",
    "        else:\n",
    "            memory_cell = nn.GRU\n",
    "\n",
    "        self.memory_cell = memory_cell(hidden_size,\n",
    "                                       OUTPUT_SIZE,\n",
    "                                       num_layers,\n",
    "                                       batch_first=True,\n",
    "                                       # make dropout 0 if num_layers is 1\n",
    "                                       dropout=drop_prob * (num_layers != 1),\n",
    "                                       bidirectional=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.memory_cell(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,  hidden_size, num_layers,\n",
    "                 device='cpu', drop_prob=0, lstm=True, feature_norm=False,\n",
    "                 input_size=300):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderRNN(hidden_size,\n",
    "                                  num_layers,\n",
    "                                  device,\n",
    "                                  drop_prob,\n",
    "                                  lstm,\n",
    "                                  feature_norm,\n",
    "                                  input_size=input_size,\n",
    "                                  )\n",
    "        self.decoder = DecoderRNN(hidden_size,\n",
    "                                  num_layers,\n",
    "                                  device,\n",
    "                                  drop_prob,\n",
    "                                  lstm,\n",
    "                                  feature_norm,\n",
    "                                  )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Actor(nn.Module):\n",
    "    \"\"\"\n",
    "    Direct application of Sequence to Sequence Network. Input a state and reply. \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,  hidden_size, num_layers,\n",
    "                 device='cuda', drop_prob=0, lstm=True, feature_norm=False,\n",
    "                 input_size=300):\n",
    "        super().__init__()\n",
    "        self.seq2seq = Seq2Seq(hidden_size=hidden_size,num_layers=num_layers,device=device, drop_prob=drop_prob, lstm=lstm, feature_norm=feature_norm,\n",
    "                          input_size = input_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        mu = self.seq2seq(x)\n",
    "        logstd = torch.zeros_like(mu)\n",
    "        std = torch.exp(logstd)\n",
    "        return mu, .001*std # Kinda guessed. \n",
    "\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    \"\"\"\n",
    "    Combination of two encoders for the state and action embeddings to predict value. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, num_layers,\n",
    "                 device='cpu', drop_prob=0, lstm=True, feature_norm=False,\n",
    "                 input_size=300):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_encoder = EncoderRNN(\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            device=device,\n",
    "            drop_prob=drop_prob,\n",
    "            lstm=lstm,\n",
    "            feature_norm=feature_norm,\n",
    "            input_size=input_size,\n",
    "                            )\n",
    "        self.action_encoder =  EncoderRNN(\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            device=device,\n",
    "            drop_prob=drop_prob,\n",
    "            lstm=lstm,\n",
    "            feature_norm=feature_norm,\n",
    "            input_size=input_size,\n",
    "                            )\n",
    "        \n",
    "        self.MLP = nn.Linear(in_features=120,out_features=1)\n",
    "        \n",
    "        \n",
    "    def forward(self,state,action):\n",
    "        state = self.state_encoder(state)\n",
    "        action = self.action_encoder(action)\n",
    "        # reshape \n",
    "        state_action = torch.cat([state,action],dim=2).reshape(-1,120)\n",
    "        state_action = F.relu(self.MLP(state_action))\n",
    "        return state_action\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Combination of two encoders for the state and action embeddings to predict value. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, num_layers,\n",
    "                 device='cpu', drop_prob=0, lstm=True, feature_norm=False,\n",
    "                 input_size=300):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_encoder = EncoderRNN(\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            device=device,\n",
    "            drop_prob=drop_prob,\n",
    "            lstm=lstm,\n",
    "            feature_norm=feature_norm,\n",
    "            input_size=input_size,\n",
    "                            )\n",
    "        self.action_encoder =  EncoderRNN(\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            device=device,\n",
    "            drop_prob=drop_prob,\n",
    "            lstm=lstm,\n",
    "            feature_norm=feature_norm,\n",
    "            input_size=input_size,\n",
    "                            )\n",
    "        \n",
    "        self.MLP = nn.Linear(in_features=120,out_features=1)\n",
    "        \n",
    "        \n",
    "    def forward(self,state,action):\n",
    "        state = self.state_encoder(state)\n",
    "        action = self.action_encoder(action)\n",
    "        # reshape \n",
    "        state_action = torch.cat([state,action],dim=2).reshape(-1,120)\n",
    "        prob = torch.sigmoid(self.MLP(state_action))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator(input_size = 300, hidden_size=1,device='cuda',num_layers=1)\n",
    "model = model.to('cuda')\n",
    "state, expert_action, raw_state, raw_expert_action = env.reset()\n",
    "state = state.to('cuda')\n",
    "expert_action = expert_action.to('cuda')\n",
    "prob = model(state.resize(1,60,300),expert_action.resize(1,60,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5029]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([state,action],dim=2).reshape(-1,120).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Policy(hidden_size=2,device='cuda',num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, expert_action, raw_state, raw_expert_action = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = state.to('cuda')\n",
    "expert_action = expert_action.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu,std = model(state.resize(1,60,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0004,  0.0147, -0.0232,  ...,  0.0033,  0.0190, -0.0076],\n",
       "          [-0.0007,  0.0199, -0.0328,  ...,  0.0029,  0.0300, -0.0119],\n",
       "          [-0.0006,  0.0213, -0.0370,  ...,  0.0017,  0.0356, -0.0143],\n",
       "          ...,\n",
       "          [ 0.0012,  0.0210, -0.0421,  ..., -0.0021,  0.0384, -0.0165],\n",
       "          [ 0.0012,  0.0210, -0.0421,  ..., -0.0021,  0.0384, -0.0165],\n",
       "          [ 0.0012,  0.0210, -0.0421,  ..., -0.0021,  0.0384, -0.0165]]],\n",
       "        device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       " tensor([[[1.0000e-07, 1.0000e-07, 1.0000e-07,  ..., 1.0000e-07,\n",
       "           1.0000e-07, 1.0000e-07],\n",
       "          [1.0000e-07, 1.0000e-07, 1.0000e-07,  ..., 1.0000e-07,\n",
       "           1.0000e-07, 1.0000e-07],\n",
       "          [1.0000e-07, 1.0000e-07, 1.0000e-07,  ..., 1.0000e-07,\n",
       "           1.0000e-07, 1.0000e-07],\n",
       "          ...,\n",
       "          [1.0000e-07, 1.0000e-07, 1.0000e-07,  ..., 1.0000e-07,\n",
       "           1.0000e-07, 1.0000e-07],\n",
       "          [1.0000e-07, 1.0000e-07, 1.0000e-07,  ..., 1.0000e-07,\n",
       "           1.0000e-07, 1.0000e-07],\n",
       "          [1.0000e-07, 1.0000e-07, 1.0000e-07,  ..., 1.0000e-07,\n",
       "           1.0000e-07, 1.0000e-07]]], device='cuda:0'))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test : Get action :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(mu, std):\n",
    "    action = torch.normal(mu, std)\n",
    "    action = action.data.numpy()\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = get_action(mu.cpu(),std.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00039523863"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0004, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    d = torch.load('./dat/preprocess/padded_vectorized_states.pt')\n",
    "    raw = torch.load('./dat/preprocess/raw_states.pt')\n",
    "\n",
    "    for index, vects in d.items():\n",
    "        # each is 60 x 300\n",
    "        input_state, next_state = vects[0], vects[1]\n",
    "        # raw strings corresponding to embeddings\n",
    "        raw_input_state, raw_next_state = list(raw.keys())[index], raw[list(raw.keys())[index]]\n",
    "        if index > 1:\n",
    "            break\n",
    "\n",
    "    dataset = DialogData(d)\n",
    "    print(len(dataset))\n",
    "    print(dataset[0][0].shape) # initial state at index 0\n",
    "    print(dataset[0][1].shape) # next state at index 0\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=5,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0,\n",
    "                                        )\n",
    "\n",
    "    model = Seq2Seq(hidden_size=2, num_layers=2)\n",
    "\n",
    "    for index, (data, target) in enumerate(loader):\n",
    "        \n",
    "        print(index, data.shape, target.shape)\n",
    "\n",
    "        # run through model to test\n",
    "        result = model(data.cpu()).detach()\n",
    "\n",
    "        print(result.shape)\n",
    "\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
