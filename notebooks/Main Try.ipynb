{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main.py file for GAIL implementation on dialog datasets.\n",
    "\n",
    "Uses command line arguments to maximize flexibility, and run many options in parallel\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from models.actor import Actor\n",
    "from models.critic import Critic\n",
    "from models.discriminator import Discriminator\n",
    "from GAIL import *\n",
    "\n",
    "from dialog_environment import DialogEnvironment\n",
    "\n",
    "device='cuda' # for now\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch GAIL for Dialog')\n",
    "\n",
    "parser.add_argument('--load_model', \n",
    "                    type=str, default=None, \n",
    "                    help='path to load the saved model')\n",
    "\n",
    "parser.add_argument('--render', \n",
    "                    action=\"store_true\", default=False, \n",
    "                    help='if you dont want to render, set this to False')\n",
    "\n",
    "parser.add_argument('--gamma', \n",
    "                    type=float, default=0.99, \n",
    "                    help='discounted factor (default: 0.99)')\n",
    "\n",
    "parser.add_argument('--lamda', \n",
    "                    type=float, default=0.98, \n",
    "                    help='GAE hyper-parameter (default: 0.98)')\n",
    "\n",
    "\n",
    "parser.add_argument('--learning_rate', \n",
    "                    type=float, default=3e-4, \n",
    "                    help='learning rate of models (default: 3e-4)')\n",
    "\n",
    "parser.add_argument('--l2_rate', \n",
    "                    type=float, default=1e-3, \n",
    "                    help='l2 regularizer coefficient (default: 1e-3)')\n",
    "\n",
    "parser.add_argument('--clip_param', \n",
    "                    type=float, default=0.2, \n",
    "                    help='clipping parameter for PPO (default: 0.2)')\n",
    "\n",
    "parser.add_argument('--discrim_update_num', \n",
    "                    type=int, default=2, \n",
    "                    help='update number of discriminator (default: 2)')\n",
    "\n",
    "parser.add_argument('--actor_critic_update_num', \n",
    "                    type=int, default=10, \n",
    "                    help='update number of actor-critic (default: 10)')\n",
    "\n",
    "parser.add_argument('--total_sample_size', \n",
    "                    type=int, default=2048, \n",
    "                    help='total sample size to collect before PPO update (default: 2048)')\n",
    "\n",
    "parser.add_argument('--batch_size', \n",
    "                    type=int, default=128, \n",
    "                    help='batch size to update (default: 128)')\n",
    "\n",
    "parser.add_argument('--suspend_accu_exp', \n",
    "                    type=float, default=0.8,\n",
    "                    help='accuracy for suspending discriminator about expert data (default: 0.8)')\n",
    "\n",
    "parser.add_argument('--suspend_accu_gen', \n",
    "                    type=float, default=0.8,\n",
    "                    help='accuracy for suspending discriminator about generated data (default: 0.8)')\n",
    "\n",
    "parser.add_argument('--max_iter_num', \n",
    "                    type=int, default=4000,\n",
    "                    help='maximal number of main iterations (default: 4000)')\n",
    "\n",
    "parser.add_argument('--seed', \n",
    "                    type=int, default=500,\n",
    "                    help='random seed (default: 500)')\n",
    "\n",
    "parser.add_argument('--logdir', \n",
    "                    type=str, default='logs/EXPERIMENTNAME',\n",
    "                    help='tensorboardx logs directory (default: logs/EXPERIMENTNAME)')\n",
    "\n",
    "parser.add_argument('--hidden_size', \n",
    "                    type=int, default=8,\n",
    "                    help='New sequence length of the representation produced by the encoder/decoder RNNs. (default: 8)')\n",
    "parser.add_argument('--num_layers', \n",
    "                    type=int, default=4,\n",
    "                    help='Number of layers in the respective RNNs (default: 4)')\n",
    "\n",
    "parser.add_argument('--seq_len', \n",
    "                    type=int, default=60,\n",
    "                    help='length of input and response sequences (default: 60, which is also max)')\n",
    "parser.add_argument('--input_size', \n",
    "                    type=int, default=300,\n",
    "                    help='DO NOT CHANGE UNLESS NEW EMBEDDINGS ARE MADE. Dimensionality of embeddings (default: 300)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = DialogEnvironment()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    #TODO\n",
    "    actor = Actor(hidden_size=args.hidden_size,num_layers=args.num_layers,device='cuda',input_size=args.input_size,output_size=args.input_size//2)\n",
    "    critic = Critic(hidden_size=args.hidden_size,num_layers=args.num_layers,input_size=args.input_size,seq_len=args.seq_len)\n",
    "    discrim = Discriminator(hidden_size=args.hidden_size,num_layers=args.hidden_size,input_size=args.input_size,seq_len=args.seq_len)\n",
    "    \n",
    "    actor.to(device), critic.to(device), discrim.to(device)\n",
    "    \n",
    "\n",
    "    actor_optim = optim.Adam(actor.parameters(), lr=args.learning_rate)\n",
    "    critic_optim = optim.Adam(critic.parameters(), lr=args.learning_rate, \n",
    "                              weight_decay=args.l2_rate) \n",
    "    discrim_optim = optim.Adam(discrim.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    # load demonstrations\n",
    "\n",
    "    writer = SummaryWriter(args.logdir)\n",
    "\n",
    "    if args.load_model is not None: #TODO\n",
    "        saved_ckpt_path = os.path.join(os.getcwd(), 'save_model', str(args.load_model))\n",
    "        ckpt = torch.load(saved_ckpt_path)\n",
    "\n",
    "        actor.load_state_dict(ckpt['actor'])\n",
    "        critic.load_state_dict(ckpt['critic'])\n",
    "        discrim.load_state_dict(ckpt['discrim'])\n",
    "\n",
    "\n",
    "    \n",
    "    episodes = 0\n",
    "    train_discrim_flag = True\n",
    "\n",
    "    for iter in range(args.max_iter_num):\n",
    "        actor.eval(), critic.eval()\n",
    "        memory = deque()\n",
    "\n",
    "        steps = 0\n",
    "        scores = []\n",
    "\n",
    "        while steps < args.total_sample_size: \n",
    "            state, expert_action, raw_state, raw_expert_action = env.reset()\n",
    "            score = 0\n",
    "\n",
    "            state = state[:args.seq_len,:]\n",
    "            expert_action = expert_action[:args.seq_len,:]\n",
    "            state = state.to(device)\n",
    "            expert_action = expert_action.to(device)\n",
    "            for _ in range(10000): \n",
    "\n",
    "                steps += 1\n",
    "\n",
    "                mu, std = actor(state.resize(1,args.seq_len,args.input_size)) #TODO: gotta be a better way to resize. \n",
    "                action = get_action(mu.cpu(), std.cpu())[0]\n",
    "                done= env.step(action)\n",
    "                irl_reward = get_reward(discrim, state, action, args)\n",
    "                if done:\n",
    "                    mask = 0\n",
    "                else:\n",
    "                    mask = 1\n",
    "\n",
    "\n",
    "                memory.append([state, torch.from_numpy(action).to(device), irl_reward, mask,expert_action])\n",
    "\n",
    "                score += irl_reward\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            \n",
    "            episodes += 1\n",
    "            scores.append(score)\n",
    "        \n",
    "        score_avg = np.mean(scores)\n",
    "        print('{}:: {} episode score is {:.2f}'.format(iter, episodes, score_avg))\n",
    "\n",
    "        actor.train(), critic.train(), discrim.train()\n",
    "        if train_discrim_flag:\n",
    "            expert_acc, learner_acc = train_discrim(discrim, memory, discrim_optim, args) \n",
    "            print(\"Expert: %.2f%% | Learner: %.2f%%\" % (expert_acc * 100, learner_acc * 100))\n",
    "            writer.add_scalar('log/expert_acc', float(expert_acc), iter) #logg\n",
    "            writer.add_scalar('log/learner_acc', float(learner_acc), iter) #logg\n",
    "            writer.add_scalar('log/avg_acc', float(learner_acc + expert_acc)/2, iter) #logg\n",
    "\n",
    "            if expert_acc > args.suspend_accu_exp and learner_acc > args.suspend_accu_gen:\n",
    "                train_discrim_flag = False\n",
    "                \n",
    "        train_actor_critic(actor, critic, memory, actor_optim, critic_optim, args)\n",
    "        writer.add_scalar('log/score', float(score_avg), iter)\n",
    "\n",
    "        writer.add_text('log/raw_state', raw_state[0],iter)\n",
    "        raw_action = get_raw_action(action) #TODO\n",
    "        writer.add_text('log/raw_action', raw_action,iter)\n",
    "        writer.add_text('log/raw_expert_action', raw_expert_action,iter)\n",
    "\n",
    "        if iter % 100:\n",
    "            score_avg = int(score_avg)\n",
    "\n",
    "\n",
    "            model_path = os.path.join(os.getcwd(),'save_model')\n",
    "            if not os.path.isdir(model_path):\n",
    "                os.makedirs(model_path)\n",
    "\n",
    "            ckpt_path = os.path.join(model_path, 'ckpt_'+ str(score_avg)+'.pth.tar')\n",
    "\n",
    "            save_checkpoint({\n",
    "                'actor': actor.state_dict(),\n",
    "                'critic': critic.state_dict(),\n",
    "                'discrim': discrim.state_dict(),\n",
    "                'args': args,\n",
    "                'score': score_avg,\n",
    "            }, filename=ckpt_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import Namespace\n",
    "args = Namespace(load_model=None,\n",
    "                render=False,\n",
    "                gamma=.99,\n",
    "                lamda=.98,\n",
    "                learning_rate=3e-4,\n",
    "                l2_rate=1e-3,\n",
    "                clip_param=.2,\n",
    "                discrim_update_num=10,\n",
    "                actor_critic_update_num=20,\n",
    "                total_sample_size=2048,\n",
    "                batch_size=128,\n",
    "                suspend_accu_exp=199,# won't stop\n",
    "                suspend_accu_gen=199,\n",
    "                max_iter_num=4000,\n",
    "                seed=500,\n",
    "                logdir='logs/noah',\n",
    "                 hidden_size=8,\n",
    "                 num_layers=4,\n",
    "                 seq_len=15,\n",
    "                 input_size=300\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nsk367/anaconda3/envs/irl/lib/python3.8/site-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:: 2048 episode score is 0.67\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "1:: 4096 episode score is 0.69\n",
      "Expert: 0.00% | Learner: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-efc1a598deea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log/raw_state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mraw_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_raw_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log/raw_action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log/raw_expert_action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_expert_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/nsk367/limitation-learning/src/GAIL.py\u001b[0m in \u001b[0;36mget_raw_action\u001b[0;34m(action, type, metric, cutoff, normalize)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# computes cosine similarity between a simple mean of the projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# weight vectors of the given words and the vectors for each word in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_by_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m### TODO:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/nsk367/anaconda3/envs/irl/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msimilar_by_vector\u001b[0;34m(self, vector, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \"\"\"\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     @deprecated(\n",
      "\u001b[0;32m/scratch/nsk367/anaconda3/envs/irl/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mlimited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_norm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrestrict_vocab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimited\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<__array_function__ internals>\u001b[0m(5)\u001b[0;36mdot\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> u\n",
      "> \u001b[0;32m/scratch/nsk367/anaconda3/envs/irl/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m(564)\u001b[0;36mmost_similar\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    562 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    563 \u001b[0;31m        \u001b[0mlimited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_norm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrestrict_vocab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 564 \u001b[0;31m        \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimited\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    565 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    566 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/scratch/nsk367/anaconda3/envs/irl/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m(622)\u001b[0;36msimilar_by_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    620 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    621 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m--> 622 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    623 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    624 \u001b[0;31m    @deprecated(\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/scratch/nsk367/limitation-learning/src/GAIL.py\u001b[0m(51)\u001b[0;36mget_raw_action\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     49 \u001b[0;31m            \u001b[0;31m# computes cosine similarity between a simple mean of the projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     50 \u001b[0;31m            \u001b[0;31m# weight vectors of the given words and the vectors for each word in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 51 \u001b[0;31m            \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_by_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     52 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     53 \u001b[0;31m            \u001b[0;31m### TODO:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-2-efc1a598deea>\u001b[0m(204)\u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    202 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    203 \u001b[0;31m        \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log/raw_state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 204 \u001b[0;31m        \u001b[0mraw_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_raw_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    205 \u001b[0;31m        \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log/raw_action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    206 \u001b[0;31m        \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log/raw_expert_action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_expert_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> action\n",
      "array([[ 1.1181632 , -0.2320432 , -0.7449156 , ...,  0.5936923 ,\n",
      "         0.9124137 , -0.19464913],\n",
      "       [ 0.32716846,  1.8732378 ,  1.4356967 , ..., -1.1859107 ,\n",
      "        -0.097253  , -0.43177202],\n",
      "       [-1.2215712 ,  0.83380455,  0.6391861 , ..., -0.17977268,\n",
      "        -0.30362248,  0.50250137],\n",
      "       ...,\n",
      "       [-0.7565528 , -0.42673633, -1.4525012 , ...,  1.6668931 ,\n",
      "         1.6387165 , -0.43140393],\n",
      "       [-0.5475479 ,  0.1943636 , -0.6181787 , ...,  0.27451918,\n",
      "        -0.46196127,  1.331673  ],\n",
      "       [-0.893766  ,  0.7435373 ,  0.99210656, ..., -0.35747856,\n",
      "         0.8762775 ,  0.15719907]], dtype=float32)\n",
      "ipdb> raw_expert_action\n",
      "'Cut it out . '\n",
      "ipdb> expert_action\n",
      "tensor([[ 0.0368,  0.4092, -0.5214,  ..., -0.0486, -0.0909,  0.2859],\n",
      "        [-0.4716,  0.2515, -0.3666,  ..., -0.2131, -0.2052,  0.0603],\n",
      "        [-0.0842, -0.0584,  0.1505,  ..., -0.3080, -0.3686, -0.8795],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "ipdb> action\n",
      "array([[ 1.1181632 , -0.2320432 , -0.7449156 , ...,  0.5936923 ,\n",
      "         0.9124137 , -0.19464913],\n",
      "       [ 0.32716846,  1.8732378 ,  1.4356967 , ..., -1.1859107 ,\n",
      "        -0.097253  , -0.43177202],\n",
      "       [-1.2215712 ,  0.83380455,  0.6391861 , ..., -0.17977268,\n",
      "        -0.30362248,  0.50250137],\n",
      "       ...,\n",
      "       [-0.7565528 , -0.42673633, -1.4525012 , ...,  1.6668931 ,\n",
      "         1.6387165 , -0.43140393],\n",
      "       [-0.5475479 ,  0.1943636 , -0.6181787 , ...,  0.27451918,\n",
      "        -0.46196127,  1.331673  ],\n",
      "       [-0.893766  ,  0.7435373 ,  0.99210656, ..., -0.35747856,\n",
      "         0.8762775 ,  0.15719907]], dtype=float32)\n",
      "ipdb> expert_action.mean(\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "ipdb> expert_action.mean()\n",
      "tensor(-0.0039, device='cuda:0')\n",
      "ipdb> action.mean()\n",
      "-0.0098813325\n",
      "ipdb> expert_action.shape\n",
      "torch.Size([15, 300])\n",
      "ipdb> expert_action.std()\n",
      "tensor(0.1739, device='cuda:0')\n",
      "ipdb> action.std()\n",
      "1.0035316\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make expert action and ours normalized. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
