{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main.py file for GAIL implementation on dialog datasets.\n",
    "\n",
    "Uses command line arguments to maximize flexibility, and run many options in parallel\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys \n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from models.actor import Actor\n",
    "from models.critic import Critic\n",
    "from models.discriminator import Discriminator\n",
    "from GAIL import *\n",
    "\n",
    "from dialog_environment import DialogEnvironment\n",
    "\n",
    "device='cuda' # for now\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Limitation Learning')\n",
    "\n",
    "parser.add_argument('--load_model', \n",
    "                    type=str, default=None, \n",
    "                    help='path to load the saved model')\n",
    "\n",
    "parser.add_argument('--gamma', \n",
    "                    type=float, default=0.99, \n",
    "                    help='discounted factor (default: 0.99)')\n",
    "\n",
    "parser.add_argument('--lamda', \n",
    "                    type=float, default=0.98, \n",
    "                    help='GAE hyper-parameter (default: 0.98)')\n",
    "\n",
    "\n",
    "parser.add_argument('--learning_rate', \n",
    "                    type=float, default=3e-4, \n",
    "                    help='learning rate of models (default: 3e-4)')\n",
    "\n",
    "parser.add_argument('--l2_rate', \n",
    "                    type=float, default=1e-3, \n",
    "                    help='l2 regularizer coefficient (default: 1e-3)')\n",
    "\n",
    "parser.add_argument('--clip_param', \n",
    "                    type=float, default=0.2, \n",
    "                    help='clipping parameter for PPO (default: 0.2)')\n",
    "\n",
    "parser.add_argument('--discrim_update_num', \n",
    "                    type=int, default=2, \n",
    "                    help='update number of discriminator (default: 2)')\n",
    "\n",
    "parser.add_argument('--actor_critic_update_num', \n",
    "                    type=int, default=10, \n",
    "                    help='update number of actor-critic (default: 10)')\n",
    "\n",
    "parser.add_argument('--total_sample_size', \n",
    "                    type=int, default=2048, \n",
    "                    help='total sample size to collect before PPO update (default: 2048)')\n",
    "\n",
    "parser.add_argument('--batch_size', \n",
    "                    type=int, default=128, \n",
    "                    help='batch size to update (default: 128)')\n",
    "\n",
    "parser.add_argument('--suspend_accu_exp', \n",
    "                    type=float, default=None,\n",
    "                    help='accuracy for suspending discriminator about expert data (default: None)')\n",
    "\n",
    "parser.add_argument('--suspend_accu_gen', \n",
    "                    type=float, default=None,\n",
    "                    help='accuracy for suspending discriminator about generated data (default: None)')\n",
    "\n",
    "parser.add_argument('--max_iter_num', \n",
    "                    type=int, default=4096,\n",
    "                    help='maximal number of main iterations (default: 4000)')\n",
    "\n",
    "parser.add_argument('--seed', \n",
    "                    type=int, default=42,\n",
    "                    help='random seed (default: 500)')\n",
    "\n",
    "parser.add_argument('--logdir', \n",
    "                    type=str, default='logs/EXPERIMENTNAME',\n",
    "                    help='tensorboardx logs directory (default: logs/EXPERIMENTNAME)')\n",
    "\n",
    "parser.add_argument('--hidden_size', \n",
    "                    type=int, default=128,\n",
    "                    help='New sequence length of the representation produced by the encoder/decoder RNNs. (default: 1024)')\n",
    "parser.add_argument('--num_layers', \n",
    "                    type=int, default=2,\n",
    "                    help='Number of layers in the respective RNNs (default: 2)')\n",
    "\n",
    "parser.add_argument('--seq_len', \n",
    "                    type=int, default=10,\n",
    "                    help='length of input and response sequences (default: 60, which is also max)')\n",
    "parser.add_argument('--input_size', \n",
    "                    type=int, default=300,\n",
    "                    help='DO NOT CHANGE UNLESS NEW EMBEDDINGS ARE MADE. Dimensionality of embeddings (default: 300)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = DialogEnvironment()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    #TODO\n",
    "    actor = Actor(hidden_size=args.hidden_size,num_layers=args.num_layers,device='cuda',input_size=args.input_size,output_size=args.input_size)\n",
    "    critic = Critic(hidden_size=args.hidden_size,num_layers=args.num_layers,input_size=args.input_size,seq_len=args.seq_len)\n",
    "    discrim = Discriminator(hidden_size=args.hidden_size,num_layers=args.hidden_size,input_size=args.input_size,seq_len=args.seq_len)\n",
    "    \n",
    "    actor.to(device), critic.to(device), discrim.to(device)\n",
    "    \n",
    "    actor_optim = optim.Adam(actor.parameters(), lr=args.learning_rate)\n",
    "    critic_optim = optim.Adam(critic.parameters(), lr=args.learning_rate, \n",
    "                              weight_decay=args.l2_rate) \n",
    "    discrim_optim = optim.Adam(discrim.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    # load demonstrations\n",
    "\n",
    "    writer = SummaryWriter(args.logdir)\n",
    "\n",
    "    if args.load_model is not None: #TODO\n",
    "        saved_ckpt_path = os.path.join(os.getcwd(), 'save_model', str(args.load_model))\n",
    "        ckpt = torch.load(saved_ckpt_path)\n",
    "\n",
    "        actor.load_state_dict(ckpt['actor'])\n",
    "        critic.load_state_dict(ckpt['critic'])\n",
    "        discrim.load_state_dict(ckpt['discrim'])\n",
    "\n",
    "\n",
    "    \n",
    "    episodes = 0\n",
    "    train_discrim_flag = True\n",
    "\n",
    "    for iter in range(args.max_iter_num):\n",
    "        actor.eval(), critic.eval()\n",
    "        memory = deque()\n",
    "\n",
    "        steps = 0\n",
    "        scores = []\n",
    "        similarity_scores = []\n",
    "        while steps < args.total_sample_size: \n",
    "            state, expert_action, raw_state, raw_expert_action = env.reset()\n",
    "            score = 0\n",
    "            similarity_score = 0\n",
    "            state = state[:args.seq_len,:]\n",
    "            expert_action = expert_action[:args.seq_len,:]\n",
    "            state = state.to(device)\n",
    "            expert_action = expert_action.to(device)\n",
    "            for _ in range(10000): \n",
    "\n",
    "                steps += 1\n",
    "\n",
    "                mu, std = actor(state.resize(1,args.seq_len,args.input_size)) #TODO: gotta be a better way to resize. \n",
    "                action = get_action(mu.cpu(), std.cpu())[0]\n",
    "                done= env.step(action)\n",
    "                irl_reward = get_reward(discrim, state, action, args)\n",
    "                if done:\n",
    "                    mask = 0\n",
    "                else:\n",
    "                    mask = 1\n",
    "\n",
    "\n",
    "                memory.append([state, torch.from_numpy(action).to(device), irl_reward, mask,expert_action])\n",
    "                score += irl_reward\n",
    "           #     similarity_score += get_cosine_sim(action,expert_action)\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            episodes += 1\n",
    "            scores.append(score)\n",
    "           # similarity_scores.append(similarity_score)\n",
    "\n",
    "        score_avg = np.mean(scores)\n",
    "      #  similarity_score_avg = np.mean(similarity_scores)\n",
    "        print('{}:: {} episode score is {:.2f}'.format(iter, episodes, score_avg))\n",
    "       # print('{}:: {} episode similarity score is {:.2f}'.format(iter, episodes, similarity_score_avg))\n",
    "\n",
    "        actor.train(), critic.train(), discrim.train()\n",
    "        if train_discrim_flag:\n",
    "            expert_acc, learner_acc = train_discrim(discrim, memory, discrim_optim, args) \n",
    "            print(\"Expert: %.2f%% | Learner: %.2f%%\" % (expert_acc * 100, learner_acc * 100))\n",
    "            writer.add_scalar('log/expert_acc', float(expert_acc), iter) #logg\n",
    "            writer.add_scalar('log/learner_acc', float(learner_acc), iter) #logg\n",
    "            writer.add_scalar('log/avg_acc', float(learner_acc + expert_acc)/2, iter) #logg\n",
    "            if args.suspend_accu_exp is not None: #only if not None do we check.\n",
    "                if expert_acc > args.suspend_accu_exp and learner_acc > args.suspend_accu_gen:\n",
    "                    train_discrim_flag = False\n",
    "                    \n",
    "        train_actor_critic(actor, critic, memory, actor_optim, critic_optim, args)\n",
    "        writer.add_scalar('log/score', float(score_avg), iter)\n",
    "     #   writer.add_scalar('log/similarity_score', float(similarity_score_avg), iter)\n",
    "        writer.add_text('log/raw_state', raw_state[0],iter)\n",
    "        raw_action = get_raw_action(action) #TODO\n",
    "        writer.add_text('log/raw_action', raw_action,iter)\n",
    "        writer.add_text('log/raw_expert_action', raw_expert_action,iter)\n",
    "\n",
    "        if iter % 100:\n",
    "            score_avg = int(score_avg)\n",
    "\n",
    "            print(raw_action)\n",
    "            model_path = os.path.join(os.getcwd(),'save_model')\n",
    "            if not os.path.isdir(model_path):\n",
    "                os.makedirs(model_path)\n",
    "\n",
    "            ckpt_path = os.path.join(model_path, 'ckpt_'+ str(score_avg)+'.pth.tar')\n",
    "\n",
    "            save_checkpoint({\n",
    "                'actor': actor.state_dict(),\n",
    "                'critic': critic.state_dict(),\n",
    "                'discrim': discrim.state_dict(),\n",
    "                'args': args,\n",
    "                'score': score_avg,\n",
    "            }, filename=ckpt_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import Namespace\n",
    "args = Namespace(load_model=None,\n",
    "                render=False,\n",
    "                gamma=.99,\n",
    "                lamda=.98,\n",
    "                learning_rate=1e-4,\n",
    "                l2_rate=1e-3,\n",
    "                clip_param=.2,\n",
    "                discrim_update_num=2,\n",
    "                actor_critic_update_num=10,\n",
    "                total_sample_size=100,\n",
    "                batch_size=100,\n",
    "                suspend_accu_exp=None,# won't stop\n",
    "                suspend_accu_gen=None,\n",
    "                max_iter_num=4000,\n",
    "                seed=500,\n",
    "                logdir='logs/noah321',\n",
    "                 hidden_size=1,\n",
    "                 num_layers=1,\n",
    "                 seq_len=5,\n",
    "                 input_size=50\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:: 100 episode score is 0.79\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "1:: 200 episode score is 0.79\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "2:: 300 episode score is 0.78\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "3:: 400 episode score is 0.78\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "4:: 500 episode score is 0.78\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "5:: 600 episode score is 0.78\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "6:: 700 episode score is 0.77\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "7:: 800 episode score is 0.77\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "8:: 900 episode score is 0.77\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "9:: 1000 episode score is 0.77\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "10:: 1100 episode score is 0.77\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "11:: 1200 episode score is 0.77\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "12:: 1300 episode score is 0.76\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "13:: 1400 episode score is 0.76\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "14:: 1500 episode score is 0.76\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "15:: 1600 episode score is 0.76\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "16:: 1700 episode score is 0.76\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "17:: 1800 episode score is 0.75\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "18:: 1900 episode score is 0.75\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "19:: 2000 episode score is 0.75\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "20:: 2100 episode score is 0.75\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "21:: 2200 episode score is 0.74\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "22:: 2300 episode score is 0.74\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "23:: 2400 episode score is 0.74\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "24:: 2500 episode score is 0.74\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "25:: 2600 episode score is 0.74\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "26:: 2700 episode score is 0.73\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "27:: 2800 episode score is 0.73\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "28:: 2900 episode score is 0.73\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "29:: 3000 episode score is 0.73\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "30:: 3100 episode score is 0.73\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "31:: 3200 episode score is 0.73\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "32:: 3300 episode score is 0.72\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "33:: 3400 episode score is 0.72\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "34:: 3500 episode score is 0.72\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "35:: 3600 episode score is 0.72\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "36:: 3700 episode score is 0.72\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "37:: 3800 episode score is 0.71\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "38:: 3900 episode score is 0.71\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "- - - - -\n",
      "39:: 4000 episode score is 0.71\n",
      "Expert: 100.00% | Learner: 1.00%\n",
      "- - - - -\n",
      "40:: 4100 episode score is 0.71\n",
      "Expert: 100.00% | Learner: 2.00%\n",
      "- - - - -\n",
      "41:: 4200 episode score is 0.71\n",
      "Expert: 100.00% | Learner: 2.00%\n",
      "- - - - -\n",
      "42:: 4300 episode score is 0.71\n",
      "Expert: 100.00% | Learner: 6.00%\n",
      "- - - - -\n",
      "43:: 4400 episode score is 0.70\n",
      "Expert: 100.00% | Learner: 4.00%\n",
      "- - - - -\n",
      "44:: 4500 episode score is 0.70\n",
      "Expert: 100.00% | Learner: 7.00%\n",
      "- - - - -\n",
      "45:: 4600 episode score is 0.70\n",
      "Expert: 100.00% | Learner: 24.00%\n",
      "- - - - -\n",
      "46:: 4700 episode score is 0.70\n",
      "Expert: 100.00% | Learner: 22.00%\n",
      "- - - - -\n",
      "47:: 4800 episode score is 0.70\n",
      "Expert: 100.00% | Learner: 28.00%\n",
      "- - - - -\n",
      "48:: 4900 episode score is 0.70\n",
      "Expert: 100.00% | Learner: 38.00%\n",
      "- - - - -\n",
      "49:: 5000 episode score is 0.69\n",
      "Expert: 97.00% | Learner: 51.00%\n",
      "- - - - -\n",
      "50:: 5100 episode score is 0.69\n",
      "Expert: 100.00% | Learner: 61.00%\n",
      "- - - - -\n",
      "51:: 5200 episode score is 0.69\n",
      "Expert: 93.00% | Learner: 70.00%\n",
      "- - - - -\n",
      "52:: 5300 episode score is 0.69\n",
      "Expert: 97.00% | Learner: 76.00%\n",
      "- - - - -\n",
      "53:: 5400 episode score is 0.69\n",
      "Expert: 98.00% | Learner: 79.00%\n",
      "- - - - -\n",
      "54:: 5500 episode score is 0.69\n",
      "Expert: 94.00% | Learner: 95.00%\n",
      "- - - - -\n",
      "55:: 5600 episode score is 0.69\n",
      "Expert: 94.00% | Learner: 98.00%\n",
      "- - - - -\n",
      "56:: 5700 episode score is 0.68\n",
      "Expert: 90.00% | Learner: 93.00%\n",
      "- - - - -\n",
      "57:: 5800 episode score is 0.68\n",
      "Expert: 94.00% | Learner: 97.00%\n",
      "- - - - -\n",
      "58:: 5900 episode score is 0.68\n",
      "Expert: 91.00% | Learner: 96.00%\n",
      "- - - - -\n",
      "59:: 6000 episode score is 0.68\n",
      "Expert: 81.00% | Learner: 99.00%\n",
      "- - - - -\n",
      "60:: 6100 episode score is 0.68\n",
      "Expert: 87.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "61:: 6200 episode score is 0.68\n",
      "Expert: 85.00% | Learner: 99.00%\n",
      "- - - - -\n",
      "62:: 6300 episode score is 0.68\n",
      "Expert: 77.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "63:: 6400 episode score is 0.68\n",
      "Expert: 82.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "64:: 6500 episode score is 0.67\n",
      "Expert: 75.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "65:: 6600 episode score is 0.67\n",
      "Expert: 75.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "66:: 6700 episode score is 0.67\n",
      "Expert: 74.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "67:: 6800 episode score is 0.67\n",
      "Expert: 71.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "68:: 6900 episode score is 0.67\n",
      "Expert: 70.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "69:: 7000 episode score is 0.67\n",
      "Expert: 61.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "70:: 7100 episode score is 0.67\n",
      "Expert: 74.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "71:: 7200 episode score is 0.67\n",
      "Expert: 71.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "72:: 7300 episode score is 0.66\n",
      "Expert: 64.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "73:: 7400 episode score is 0.66\n",
      "Expert: 64.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "74:: 7500 episode score is 0.66\n",
      "Expert: 72.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "75:: 7600 episode score is 0.66\n",
      "Expert: 70.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "76:: 7700 episode score is 0.66\n",
      "Expert: 67.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "77:: 7800 episode score is 0.66\n",
      "Expert: 60.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "78:: 7900 episode score is 0.66\n",
      "Expert: 57.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "79:: 8000 episode score is 0.66\n",
      "Expert: 63.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "80:: 8100 episode score is 0.66\n",
      "Expert: 57.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "81:: 8200 episode score is 0.66\n",
      "Expert: 62.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "82:: 8300 episode score is 0.65\n",
      "Expert: 66.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "83:: 8400 episode score is 0.65\n",
      "Expert: 58.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "84:: 8500 episode score is 0.65\n",
      "Expert: 58.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "85:: 8600 episode score is 0.65\n",
      "Expert: 58.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "86:: 8700 episode score is 0.65\n",
      "Expert: 54.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "87:: 8800 episode score is 0.65\n",
      "Expert: 55.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "88:: 8900 episode score is 0.65\n",
      "Expert: 55.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "89:: 9000 episode score is 0.65\n",
      "Expert: 62.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "90:: 9100 episode score is 0.65\n",
      "Expert: 54.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "91:: 9200 episode score is 0.65\n",
      "Expert: 61.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "92:: 9300 episode score is 0.65\n",
      "Expert: 62.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "93:: 9400 episode score is 0.64\n",
      "Expert: 60.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "94:: 9500 episode score is 0.64\n",
      "Expert: 52.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "95:: 9600 episode score is 0.64\n",
      "Expert: 57.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "96:: 9700 episode score is 0.64\n",
      "Expert: 61.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "97:: 9800 episode score is 0.64\n",
      "Expert: 50.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "98:: 9900 episode score is 0.64\n",
      "Expert: 59.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "99:: 10000 episode score is 0.64\n",
      "Expert: 56.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "100:: 10100 episode score is 0.64\n",
      "Expert: 58.00% | Learner: 100.00%\n",
      "101:: 10200 episode score is 0.64\n",
      "Expert: 63.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "102:: 10300 episode score is 0.64\n",
      "Expert: 60.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "103:: 10400 episode score is 0.64\n",
      "Expert: 59.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "104:: 10500 episode score is 0.64\n",
      "Expert: 65.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "105:: 10600 episode score is 0.63\n",
      "Expert: 60.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "106:: 10700 episode score is 0.64\n",
      "Expert: 60.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "107:: 10800 episode score is 0.63\n",
      "Expert: 62.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "108:: 10900 episode score is 0.63\n",
      "Expert: 55.00% | Learner: 100.00%\n",
      "- - - - -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109:: 11000 episode score is 0.63\n",
      "Expert: 57.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "110:: 11100 episode score is 0.63\n",
      "Expert: 62.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "111:: 11200 episode score is 0.63\n",
      "Expert: 58.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "112:: 11300 episode score is 0.63\n",
      "Expert: 64.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "113:: 11400 episode score is 0.63\n",
      "Expert: 66.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "114:: 11500 episode score is 0.63\n",
      "Expert: 58.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "115:: 11600 episode score is 0.63\n",
      "Expert: 57.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "116:: 11700 episode score is 0.63\n",
      "Expert: 68.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "117:: 11800 episode score is 0.63\n",
      "Expert: 64.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "118:: 11900 episode score is 0.62\n",
      "Expert: 64.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "119:: 12000 episode score is 0.63\n",
      "Expert: 65.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "120:: 12100 episode score is 0.62\n",
      "Expert: 66.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "121:: 12200 episode score is 0.62\n",
      "Expert: 64.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "122:: 12300 episode score is 0.62\n",
      "Expert: 63.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "123:: 12400 episode score is 0.62\n",
      "Expert: 64.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "124:: 12500 episode score is 0.62\n",
      "Expert: 66.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "125:: 12600 episode score is 0.62\n",
      "Expert: 67.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "126:: 12700 episode score is 0.62\n",
      "Expert: 68.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "127:: 12800 episode score is 0.62\n",
      "Expert: 57.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "128:: 12900 episode score is 0.62\n",
      "Expert: 66.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "129:: 13000 episode score is 0.62\n",
      "Expert: 53.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "130:: 13100 episode score is 0.62\n",
      "Expert: 66.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "131:: 13200 episode score is 0.61\n",
      "Expert: 69.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "132:: 13300 episode score is 0.62\n",
      "Expert: 65.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "133:: 13400 episode score is 0.61\n",
      "Expert: 77.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "134:: 13500 episode score is 0.61\n",
      "Expert: 64.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "135:: 13600 episode score is 0.61\n",
      "Expert: 66.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "136:: 13700 episode score is 0.61\n",
      "Expert: 66.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "137:: 13800 episode score is 0.61\n",
      "Expert: 67.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "138:: 13900 episode score is 0.61\n",
      "Expert: 63.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "139:: 14000 episode score is 0.61\n",
      "Expert: 70.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "140:: 14100 episode score is 0.61\n",
      "Expert: 69.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "141:: 14200 episode score is 0.61\n",
      "Expert: 77.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "142:: 14300 episode score is 0.61\n",
      "Expert: 69.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "143:: 14400 episode score is 0.61\n",
      "Expert: 75.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "144:: 14500 episode score is 0.61\n",
      "Expert: 69.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "145:: 14600 episode score is 0.60\n",
      "Expert: 71.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "146:: 14700 episode score is 0.60\n",
      "Expert: 79.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "147:: 14800 episode score is 0.60\n",
      "Expert: 77.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "148:: 14900 episode score is 0.60\n",
      "Expert: 74.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "149:: 15000 episode score is 0.60\n",
      "Expert: 73.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "150:: 15100 episode score is 0.60\n",
      "Expert: 77.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "151:: 15200 episode score is 0.60\n",
      "Expert: 77.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "152:: 15300 episode score is 0.60\n",
      "Expert: 75.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "153:: 15400 episode score is 0.60\n",
      "Expert: 71.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "154:: 15500 episode score is 0.60\n",
      "Expert: 79.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "155:: 15600 episode score is 0.60\n",
      "Expert: 80.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "156:: 15700 episode score is 0.60\n",
      "Expert: 74.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "157:: 15800 episode score is 0.59\n",
      "Expert: 76.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "158:: 15900 episode score is 0.59\n",
      "Expert: 75.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "159:: 16000 episode score is 0.59\n",
      "Expert: 78.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "160:: 16100 episode score is 0.59\n",
      "Expert: 77.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "161:: 16200 episode score is 0.59\n",
      "Expert: 74.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "162:: 16300 episode score is 0.59\n",
      "Expert: 89.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "163:: 16400 episode score is 0.59\n",
      "Expert: 84.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "164:: 16500 episode score is 0.59\n",
      "Expert: 83.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "165:: 16600 episode score is 0.59\n",
      "Expert: 82.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "166:: 16700 episode score is 0.59\n",
      "Expert: 87.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "167:: 16800 episode score is 0.58\n",
      "Expert: 79.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "168:: 16900 episode score is 0.58\n",
      "Expert: 85.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "169:: 17000 episode score is 0.58\n",
      "Expert: 87.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "170:: 17100 episode score is 0.58\n",
      "Expert: 86.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "171:: 17200 episode score is 0.58\n",
      "Expert: 85.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "172:: 17300 episode score is 0.58\n",
      "Expert: 82.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "173:: 17400 episode score is 0.58\n",
      "Expert: 84.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "174:: 17500 episode score is 0.58\n",
      "Expert: 84.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "175:: 17600 episode score is 0.57\n",
      "Expert: 85.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "176:: 17700 episode score is 0.57\n",
      "Expert: 83.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "177:: 17800 episode score is 0.57\n",
      "Expert: 88.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "178:: 17900 episode score is 0.57\n",
      "Expert: 89.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "179:: 18000 episode score is 0.57\n",
      "Expert: 88.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "180:: 18100 episode score is 0.57\n",
      "Expert: 86.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "181:: 18200 episode score is 0.57\n",
      "Expert: 87.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "182:: 18300 episode score is 0.57\n",
      "Expert: 91.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "183:: 18400 episode score is 0.57\n",
      "Expert: 91.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "184:: 18500 episode score is 0.56\n",
      "Expert: 88.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "185:: 18600 episode score is 0.56\n",
      "Expert: 89.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "186:: 18700 episode score is 0.56\n",
      "Expert: 82.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "187:: 18800 episode score is 0.56\n",
      "Expert: 90.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "188:: 18900 episode score is 0.56\n",
      "Expert: 87.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "189:: 19000 episode score is 0.56\n",
      "Expert: 90.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "190:: 19100 episode score is 0.56\n",
      "Expert: 93.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "191:: 19200 episode score is 0.56\n",
      "Expert: 93.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "192:: 19300 episode score is 0.56\n",
      "Expert: 96.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "193:: 19400 episode score is 0.56\n",
      "Expert: 93.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "194:: 19500 episode score is 0.55\n",
      "Expert: 90.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "195:: 19600 episode score is 0.55\n",
      "Expert: 85.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "196:: 19700 episode score is 0.55\n",
      "Expert: 96.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "197:: 19800 episode score is 0.55\n",
      "Expert: 91.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "198:: 19900 episode score is 0.55\n",
      "Expert: 93.00% | Learner: 100.00%\n",
      "- - - - -\n",
      "199:: 20000 episode score is 0.55\n",
      "Expert: 92.00% | Learner: 100.00%\n",
      "- - - - -\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-7d175b6fa1f1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0msimilarity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_sample_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_expert_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0msimilarity_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/nsk367/deepRL/limitation-learning/src/dialog_environment.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mraw_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_conversations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mraw_expert_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_conversations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_conversations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m#TODO: truncate sequences?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_expert_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/scratch/nsk367/deepRL/limitation-learning/src/dialog_environment.py\u001b[0m(73)\u001b[0;36mreset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     71 \u001b[0;31m        \u001b[0mraw_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_conversations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 73 \u001b[0;31m        \u001b[0mraw_expert_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_conversations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_conversations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m        \u001b[0;31m#TODO: truncate sequences?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_expert_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> action\n",
      "*** NameError: name 'action' is not defined\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-6-7d175b6fa1f1>\u001b[0m(152)\u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    150 \u001b[0;31m        \u001b[0msimilarity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    151 \u001b[0;31m        \u001b[0;32mwhile\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_sample_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 152 \u001b[0;31m            \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_expert_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    153 \u001b[0;31m            \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    154 \u001b[0;31m            \u001b[0msimilarity_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> action\n",
      "array([[-0.21156065, -0.18256246, -0.08050326, -0.0652514 ,  0.04251666,\n",
      "        -0.02773855, -0.24343662,  0.12282405,  0.13769267, -0.02386661,\n",
      "        -0.09503883, -0.10776423, -0.08362972,  0.21561046, -0.03535365,\n",
      "         0.06936019,  0.05550934,  0.08944046,  0.11968394, -0.13345319,\n",
      "         0.15214626, -0.11029126,  0.20060107,  0.14278947, -0.18546948,\n",
      "         0.12476933, -0.26044592,  0.04834222,  0.1893165 , -0.05447681,\n",
      "        -0.07250769, -0.21191359,  0.02162006,  0.16728736,  0.14657353,\n",
      "         0.17160411, -0.19045049,  0.04304926, -0.22181834,  0.01128194,\n",
      "         0.08227973,  0.09561264, -0.22143847, -0.18083803,  0.22535007,\n",
      "         0.14201313,  0.03417401, -0.14212191,  0.1450342 , -0.00731616],\n",
      "       [-0.20685706, -0.17532365, -0.08341163, -0.06964613,  0.0383218 ,\n",
      "        -0.02430027, -0.2352157 ,  0.13450395,  0.12803677, -0.02641394,\n",
      "        -0.08028635, -0.11198969, -0.08510809,  0.23046824, -0.03628832,\n",
      "         0.06674785,  0.05013053,  0.09124137,  0.12538335, -0.12660736,\n",
      "         0.15588546, -0.10847362,  0.21289401,  0.14866021, -0.17448   ,\n",
      "         0.13493626, -0.26927546,  0.05955412,  0.20707093, -0.059484  ,\n",
      "        -0.07233526, -0.2017518 ,  0.02590708,  0.16283986,  0.14400533,\n",
      "         0.173168  , -0.19555032,  0.03538651, -0.21904132, -0.00065553,\n",
      "         0.08806253,  0.09466079, -0.22371311, -0.17546621,  0.23000963,\n",
      "         0.14731178,  0.02237533, -0.14882295,  0.14205004, -0.00543089],\n",
      "       [-0.21343696, -0.18572363, -0.07996908, -0.06932457,  0.04601976,\n",
      "        -0.02235927, -0.22739759,  0.12813711,  0.12892756, -0.02198218,\n",
      "        -0.07804928, -0.09889384, -0.07855404,  0.22351998, -0.02888981,\n",
      "         0.06567857,  0.06263857,  0.09075484,  0.12476344, -0.1399465 ,\n",
      "         0.16394845, -0.11110295,  0.21468529,  0.13891533, -0.18460207,\n",
      "         0.13448839, -0.27094752,  0.05655026,  0.18594742, -0.0574157 ,\n",
      "        -0.07208455, -0.20070823,  0.02471872,  0.15845257,  0.14368129,\n",
      "         0.1629849 , -0.19239485,  0.04273387, -0.21795158,  0.00937535,\n",
      "         0.08330339,  0.09466717, -0.22106268, -0.17411168,  0.23163797,\n",
      "         0.15087008,  0.02883726, -0.13849254,  0.14345457,  0.00302038],\n",
      "       [-0.20624101, -0.19181018, -0.07747902, -0.07002389,  0.04048432,\n",
      "        -0.02370806, -0.23266774,  0.12247899,  0.11931687, -0.02114777,\n",
      "        -0.08606194, -0.11242926, -0.08780732,  0.23216583, -0.03908249,\n",
      "         0.07368406,  0.05663566,  0.09118937,  0.11713091, -0.1319516 ,\n",
      "         0.15370433, -0.10402653,  0.20656034,  0.14012262, -0.18904464,\n",
      "         0.12676236, -0.25803483,  0.06606348,  0.186451  , -0.05440877,\n",
      "        -0.06006765, -0.21429677,  0.02702545,  0.16478588,  0.15746437,\n",
      "         0.17624867, -0.19835849,  0.0330161 , -0.23201524, -0.00048744,\n",
      "         0.09382002,  0.0936838 , -0.22307886, -0.18009914,  0.22684649,\n",
      "         0.160478  ,  0.02339021, -0.15181687,  0.12888315, -0.00670271],\n",
      "       [-0.21965829, -0.19761407, -0.0821426 , -0.08017772,  0.0416563 ,\n",
      "        -0.01257942, -0.24011   ,  0.10999534,  0.1284539 , -0.02432732,\n",
      "        -0.08462125, -0.10746174, -0.08200406,  0.23098187, -0.04479876,\n",
      "         0.07917532,  0.04977694,  0.0865694 ,  0.12186114, -0.12542717,\n",
      "         0.15945694, -0.11640162,  0.20500459,  0.13291657, -0.18853387,\n",
      "         0.13311802, -0.26044843,  0.06311999,  0.17998552, -0.06487181,\n",
      "        -0.06879295, -0.20228137,  0.02570291,  0.16290171,  0.16465531,\n",
      "         0.16461556, -0.19666159,  0.03892788, -0.23429827,  0.00276372,\n",
      "         0.08573131,  0.10446935, -0.21598078, -0.18049885,  0.2272651 ,\n",
      "         0.14973493,  0.03441679, -0.14792338,  0.13857688,  0.00072824]],\n",
      "      dtype=float32)\n",
      "ipdb> expert_action\n",
      "tensor([[-3.2617e-02, -1.1053e-01,  1.4639e-01, -2.0005e-01, -1.7614e-01,\n",
      "         -5.0614e-01,  2.0148e-01,  1.6890e-02, -9.8235e-02,  7.8982e-02,\n",
      "          7.9886e-02,  5.2367e-02,  5.4396e-02, -1.0725e-01,  1.6657e-01,\n",
      "         -2.7636e-01,  9.6494e-02,  3.8591e-02,  1.5127e-03, -1.9869e-01,\n",
      "          2.1173e-02, -2.2753e-01,  2.2096e-01,  5.7258e-02, -1.3995e-01,\n",
      "          9.1006e-02,  5.9391e-02, -2.0112e-01, -1.5027e-01,  8.6390e-02,\n",
      "          1.4258e-01, -7.8901e-02,  1.2521e-01, -6.8179e-02, -9.2452e-02,\n",
      "          1.7575e-02,  1.3216e-01,  8.9988e-02,  1.0807e-02,  7.0250e-02,\n",
      "          2.8343e-03,  1.2939e-01, -4.6542e-02, -9.2333e-02,  1.3869e-01,\n",
      "         -1.3883e-01,  6.0922e-02, -4.4142e-02, -1.9771e-01,  6.6103e-03],\n",
      "        [-8.8468e-03,  3.2182e-01, -1.3283e-01,  7.2115e-02,  4.2878e-02,\n",
      "          9.0301e-02, -2.7986e-01,  1.1067e-02, -9.6873e-02, -1.8369e-01,\n",
      "          7.0362e-02, -1.6668e-02, -6.4840e-02,  1.3765e-01, -8.7398e-02,\n",
      "          1.9391e-01, -1.0889e-01,  4.6822e-02, -1.2487e-01, -2.3719e-02,\n",
      "         -3.5037e-02,  2.8815e-01, -2.4113e-01,  6.9869e-02,  8.4729e-02,\n",
      "          4.5770e-02,  2.3937e-01, -1.9695e-02, -1.5785e-01,  1.1255e-01,\n",
      "          1.6391e-01, -1.6556e-01, -1.5340e-01, -1.9282e-01,  8.4329e-02,\n",
      "         -7.4628e-02, -3.2788e-02, -1.0630e-01, -1.4345e-01, -5.6729e-02,\n",
      "          1.2612e-01, -1.5215e-01,  1.6518e-01, -4.6010e-02, -1.6947e-01,\n",
      "          1.4072e-01,  1.9864e-01, -5.5801e-02,  2.3689e-01,  8.2403e-02],\n",
      "        [ 2.6016e-02,  8.5035e-02, -2.3323e-02, -1.9200e-02,  1.6252e-01,\n",
      "          1.7940e-01,  3.0999e-01,  6.1136e-02,  1.1027e-02,  1.4960e-02,\n",
      "         -3.5899e-01,  1.5806e-01, -1.2157e-01,  1.3568e-02,  2.3283e-02,\n",
      "          1.5423e-01, -1.9983e-01,  5.2286e-02,  1.5536e-01,  3.0753e-01,\n",
      "          5.1809e-02,  1.7311e-01, -9.3641e-02, -1.2298e-01,  1.2574e-01,\n",
      "          1.5373e-01, -4.8842e-02, -1.2700e-01, -2.3659e-01,  1.0979e-02,\n",
      "         -2.0112e-01, -3.4475e-02, -7.1263e-02,  7.5869e-02, -4.6988e-02,\n",
      "          9.6022e-02,  2.8090e-02, -6.5796e-02, -2.6871e-01,  4.0202e-02,\n",
      "          5.1377e-02,  3.9130e-02, -2.3650e-01, -1.4271e-01, -1.9509e-01,\n",
      "         -9.8844e-02,  9.1761e-02,  2.1221e-02,  7.0548e-02,  1.4934e-01],\n",
      "        [ 2.9550e-01,  2.1392e-01,  9.9073e-02,  1.5537e-01,  1.6608e-01,\n",
      "         -9.8950e-02,  1.1180e-01, -3.7803e-02,  1.0711e-01, -1.7451e-01,\n",
      "         -5.5394e-02, -1.1093e-02, -1.5391e-01, -1.6626e-02,  2.2102e-01,\n",
      "          1.2197e-01,  1.1701e-02,  1.0153e-01, -1.2724e-02, -5.0403e-02,\n",
      "          1.6956e-01,  1.9680e-01,  1.0200e-01,  1.2441e-01,  2.0617e-01,\n",
      "          3.4874e-02, -2.1537e-01,  2.2572e-01, -7.7436e-02, -7.5548e-02,\n",
      "          1.4528e-01,  3.1929e-01, -1.3839e-01, -7.2002e-02,  1.8299e-01,\n",
      "          3.8919e-02, -1.6316e-02,  1.3293e-01, -1.4161e-01,  1.1966e-01,\n",
      "         -1.2807e-01,  5.2947e-02, -1.8080e-01,  6.0902e-02,  9.0047e-02,\n",
      "         -1.0079e-01,  2.4577e-02,  2.1782e-01, -1.7533e-01,  4.7148e-02],\n",
      "        [-9.6238e-02,  1.4887e-01,  1.2470e-01, -1.0162e-01,  2.7655e-02,\n",
      "         -3.6700e-02, -1.0646e-01,  2.9352e-02,  1.4420e-01,  9.8419e-02,\n",
      "          3.1931e-02,  1.2439e-01,  2.0702e-02,  1.5263e-01, -1.3162e-01,\n",
      "          1.9656e-01,  1.1818e-01,  1.2982e-01, -2.1159e-01,  1.7181e-01,\n",
      "         -3.6509e-02,  3.2751e-01,  1.2664e-01, -2.1382e-01, -7.8407e-02,\n",
      "         -2.3787e-01,  8.2156e-02, -5.8705e-02, -1.1339e-01, -5.0790e-02,\n",
      "         -1.9940e-01, -2.2112e-01,  3.7467e-02, -1.0287e-01, -9.9025e-02,\n",
      "         -7.6914e-02,  2.3898e-04, -3.4021e-01,  1.9517e-01,  2.8824e-02,\n",
      "         -2.7247e-02, -2.8038e-01, -3.8437e-02, -2.1310e-01, -3.0757e-03,\n",
      "          3.6563e-02, -1.6586e-01,  1.0669e-01, -1.7966e-02, -8.9074e-03]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> similarity_score\n",
      "0\n",
      "ipdb> similarity_scores\n",
      "[]\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action space is too obvious. Need to constrain to same, and retry. Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python ../src/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = torch.ones(100,5,1)\n",
    "advants = torch.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = advants.unsqueeze(dim=1) * ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
