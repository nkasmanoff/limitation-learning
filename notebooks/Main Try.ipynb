{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main.py file for GAIL implementation on dialog datasets.\n",
    "\n",
    "Uses command line arguments to maximize flexibility, and run many options in parallel\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys \n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from models.actor import Actor\n",
    "from models.critic import Critic\n",
    "from models.discriminator import Discriminator\n",
    "from GAIL import *\n",
    "\n",
    "from dialog_environment import DialogEnvironment\n",
    "\n",
    "device='cuda' # for now\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Limitation Learning')\n",
    "\n",
    "parser.add_argument('--load_model', \n",
    "                    type=str, default=None, \n",
    "                    help='path to load the saved model')\n",
    "\n",
    "parser.add_argument('--gamma', \n",
    "                    type=float, default=0.99, \n",
    "                    help='discounted factor (default: 0.99)')\n",
    "\n",
    "parser.add_argument('--lamda', \n",
    "                    type=float, default=0.98, \n",
    "                    help='GAE hyper-parameter (default: 0.98)')\n",
    "\n",
    "\n",
    "parser.add_argument('--learning_rate', \n",
    "                    type=float, default=3e-4, \n",
    "                    help='learning rate of models (default: 3e-4)')\n",
    "\n",
    "parser.add_argument('--l2_rate', \n",
    "                    type=float, default=1e-3, \n",
    "                    help='l2 regularizer coefficient (default: 1e-3)')\n",
    "\n",
    "parser.add_argument('--clip_param', \n",
    "                    type=float, default=0.2, \n",
    "                    help='clipping parameter for PPO (default: 0.2)')\n",
    "\n",
    "parser.add_argument('--discrim_update_num', \n",
    "                    type=int, default=2, \n",
    "                    help='update number of discriminator (default: 2)')\n",
    "\n",
    "parser.add_argument('--actor_critic_update_num', \n",
    "                    type=int, default=10, \n",
    "                    help='update number of actor-critic (default: 10)')\n",
    "\n",
    "parser.add_argument('--total_sample_size', \n",
    "                    type=int, default=2048, \n",
    "                    help='total sample size to collect before PPO update (default: 2048)')\n",
    "\n",
    "parser.add_argument('--batch_size', \n",
    "                    type=int, default=128, \n",
    "                    help='batch size to update (default: 128)')\n",
    "\n",
    "parser.add_argument('--suspend_accu_exp', \n",
    "                    type=float, default=None,\n",
    "                    help='accuracy for suspending discriminator about expert data (default: None)')\n",
    "\n",
    "parser.add_argument('--suspend_accu_gen', \n",
    "                    type=float, default=None,\n",
    "                    help='accuracy for suspending discriminator about generated data (default: None)')\n",
    "\n",
    "parser.add_argument('--max_iter_num', \n",
    "                    type=int, default=4096,\n",
    "                    help='maximal number of main iterations (default: 4000)')\n",
    "\n",
    "parser.add_argument('--seed', \n",
    "                    type=int, default=42,\n",
    "                    help='random seed (default: 500)')\n",
    "\n",
    "parser.add_argument('--logdir', \n",
    "                    type=str, default='logs/EXPERIMENTNAME',\n",
    "                    help='tensorboardx logs directory (default: logs/EXPERIMENTNAME)')\n",
    "\n",
    "parser.add_argument('--hidden_size', \n",
    "                    type=int, default=128,\n",
    "                    help='New sequence length of the representation produced by the encoder/decoder RNNs. (default: 1024)')\n",
    "parser.add_argument('--num_layers', \n",
    "                    type=int, default=2,\n",
    "                    help='Number of layers in the respective RNNs (default: 2)')\n",
    "\n",
    "parser.add_argument('--seq_len', \n",
    "                    type=int, default=10,\n",
    "                    help='length of input and response sequences (default: 60, which is also max)')\n",
    "parser.add_argument('--input_size', \n",
    "                    type=int, default=300,\n",
    "                    help='DO NOT CHANGE UNLESS NEW EMBEDDINGS ARE MADE. Dimensionality of embeddings (default: 300)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = DialogEnvironment()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    #TODO\n",
    "    actor = Actor(hidden_size=args.hidden_size,num_layers=args.num_layers,device='cuda',input_size=args.input_size,output_size=args.input_size//2)\n",
    "    critic = Critic(hidden_size=args.hidden_size,num_layers=args.num_layers,input_size=args.input_size,seq_len=args.seq_len)\n",
    "    discrim = Discriminator(hidden_size=args.hidden_size,num_layers=args.hidden_size,input_size=args.input_size,seq_len=args.seq_len)\n",
    "    \n",
    "    actor.to(device), critic.to(device), discrim.to(device)\n",
    "    \n",
    "    actor_optim = optim.Adam(actor.parameters(), lr=args.learning_rate)\n",
    "    critic_optim = optim.Adam(critic.parameters(), lr=args.learning_rate, \n",
    "                              weight_decay=args.l2_rate) \n",
    "    discrim_optim = optim.Adam(discrim.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    # load demonstrations\n",
    "\n",
    "    writer = SummaryWriter(args.logdir)\n",
    "\n",
    "    if args.load_model is not None: #TODO\n",
    "        saved_ckpt_path = os.path.join(os.getcwd(), 'save_model', str(args.load_model))\n",
    "        ckpt = torch.load(saved_ckpt_path)\n",
    "\n",
    "        actor.load_state_dict(ckpt['actor'])\n",
    "        critic.load_state_dict(ckpt['critic'])\n",
    "        discrim.load_state_dict(ckpt['discrim'])\n",
    "\n",
    "\n",
    "    \n",
    "    episodes = 0\n",
    "    train_discrim_flag = True\n",
    "\n",
    "    for iter in range(args.max_iter_num):\n",
    "        actor.eval(), critic.eval()\n",
    "        memory = deque()\n",
    "\n",
    "        steps = 0\n",
    "        scores = []\n",
    "        similarity_scores = []\n",
    "        while steps < args.total_sample_size: \n",
    "            state, expert_action, raw_state, raw_expert_action = env.reset()\n",
    "            score = 0\n",
    "            similarity_score = 0\n",
    "            state = state[:args.seq_len,:]\n",
    "            expert_action = expert_action[:args.seq_len,:]\n",
    "            state = state.to(device)\n",
    "            expert_action = expert_action.to(device)\n",
    "            for _ in range(10000): \n",
    "\n",
    "                steps += 1\n",
    "\n",
    "                mu, std = actor(state.resize(1,args.seq_len,args.input_size)) #TODO: gotta be a better way to resize. \n",
    "                action = get_action(mu.cpu(), std.cpu())[0]\n",
    "                done= env.step(action)\n",
    "                irl_reward = get_reward(discrim, state, action, args)\n",
    "                if done:\n",
    "                    mask = 0\n",
    "                else:\n",
    "                    mask = 1\n",
    "\n",
    "\n",
    "                memory.append([state, torch.from_numpy(action).to(device), irl_reward, mask,expert_action])\n",
    "                score += irl_reward\n",
    "                similarity_score += get_cosine_sim(action,expert_action)\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            episodes += 1\n",
    "            scores.append(score)\n",
    "            similarity_scores.append(similarity_score)\n",
    "\n",
    "        score_avg = np.mean(scores)\n",
    "        similarity_score_avg = np.mean(similarity_scores)\n",
    "        print('{}:: {} episode score is {:.2f}'.format(iter, episodes, score_avg))\n",
    "        print('{}:: {} episode similarity score is {:.2f}'.format(iter, episodes, similarity_score_avg))\n",
    "\n",
    "        actor.train(), critic.train(), discrim.train()\n",
    "        if train_discrim_flag:\n",
    "            expert_acc, learner_acc = train_discrim(discrim, memory, discrim_optim, args) \n",
    "            print(\"Expert: %.2f%% | Learner: %.2f%%\" % (expert_acc * 100, learner_acc * 100))\n",
    "            writer.add_scalar('log/expert_acc', float(expert_acc), iter) #logg\n",
    "            writer.add_scalar('log/learner_acc', float(learner_acc), iter) #logg\n",
    "            writer.add_scalar('log/avg_acc', float(learner_acc + expert_acc)/2, iter) #logg\n",
    "            if args.suspend_accu_exp is not None: #only if not None do we check.\n",
    "                if expert_acc > args.suspend_accu_exp and learner_acc > args.suspend_accu_gen:\n",
    "                    train_discrim_flag = False\n",
    "                    \n",
    "        train_actor_critic(actor, critic, memory, actor_optim, critic_optim, args)\n",
    "        writer.add_scalar('log/score', float(score_avg), iter)\n",
    "        writer.add_scalar('log/similarity_score', float(similarity_score_avg), iter)\n",
    "        writer.add_text('log/raw_state', raw_state[0],iter)\n",
    "        raw_action = get_raw_action(action) #TODO\n",
    "        writer.add_text('log/raw_action', raw_action,iter)\n",
    "        writer.add_text('log/raw_expert_action', raw_expert_action,iter)\n",
    "\n",
    "        if iter % 100:\n",
    "            score_avg = int(score_avg)\n",
    "\n",
    "\n",
    "            model_path = os.path.join(os.getcwd(),'save_model')\n",
    "            if not os.path.isdir(model_path):\n",
    "                os.makedirs(model_path)\n",
    "\n",
    "            ckpt_path = os.path.join(model_path, 'ckpt_'+ str(score_avg)+'.pth.tar')\n",
    "\n",
    "            save_checkpoint({\n",
    "                'actor': actor.state_dict(),\n",
    "                'critic': critic.state_dict(),\n",
    "                'discrim': discrim.state_dict(),\n",
    "                'args': args,\n",
    "                'score': score_avg,\n",
    "            }, filename=ckpt_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import Namespace\n",
    "args = Namespace(load_model=None,\n",
    "                render=False,\n",
    "                gamma=.99,\n",
    "                lamda=.98,\n",
    "                learning_rate=3e-4,\n",
    "                l2_rate=1e-3,\n",
    "                clip_param=.2,\n",
    "                discrim_update_num=2,\n",
    "                actor_critic_update_num=10,\n",
    "                total_sample_size=2048,\n",
    "                batch_size=128,\n",
    "                suspend_accu_exp=None,# won't stop\n",
    "                suspend_accu_gen=None,\n",
    "                max_iter_num=4000,\n",
    "                seed=500,\n",
    "                logdir='logs/noah2',\n",
    "                 hidden_size=32,\n",
    "                 num_layers=4,\n",
    "                 seq_len=10,\n",
    "                 input_size=300\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nsk367/anaconda3/envs/irl/lib/python3.8/site-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:: 2048 episode score is 0.74\n",
      "0:: 2048 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "1:: 4096 episode score is 0.70\n",
      "1:: 4096 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "2:: 6144 episode score is 0.68\n",
      "2:: 6144 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "3:: 8192 episode score is 0.67\n",
      "3:: 8192 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "4:: 10240 episode score is 0.68\n",
      "4:: 10240 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "5:: 12288 episode score is 0.69\n",
      "5:: 12288 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "6:: 14336 episode score is 0.70\n",
      "6:: 14336 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "7:: 16384 episode score is 0.70\n",
      "7:: 16384 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "8:: 18432 episode score is 0.70\n",
      "8:: 18432 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "9:: 20480 episode score is 0.70\n",
      "9:: 20480 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "10:: 22528 episode score is 0.69\n",
      "10:: 22528 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "11:: 24576 episode score is 0.69\n",
      "11:: 24576 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "12:: 26624 episode score is 0.69\n",
      "12:: 26624 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "13:: 28672 episode score is 0.69\n",
      "13:: 28672 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "14:: 30720 episode score is 0.69\n",
      "14:: 30720 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "15:: 32768 episode score is 0.69\n",
      "15:: 32768 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "16:: 34816 episode score is 0.70\n",
      "16:: 34816 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "17:: 36864 episode score is 0.70\n",
      "17:: 36864 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "18:: 38912 episode score is 0.70\n",
      "18:: 38912 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "19:: 40960 episode score is 0.69\n",
      "19:: 40960 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "20:: 43008 episode score is 0.69\n",
      "20:: 43008 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "21:: 45056 episode score is 0.69\n",
      "21:: 45056 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "22:: 47104 episode score is 0.69\n",
      "22:: 47104 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "23:: 49152 episode score is 0.69\n",
      "23:: 49152 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "24:: 51200 episode score is 0.69\n",
      "24:: 51200 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "25:: 53248 episode score is 0.69\n",
      "25:: 53248 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "26:: 55296 episode score is 0.69\n",
      "26:: 55296 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "27:: 57344 episode score is 0.69\n",
      "27:: 57344 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "28:: 59392 episode score is 0.69\n",
      "28:: 59392 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "29:: 61440 episode score is 0.69\n",
      "29:: 61440 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "30:: 63488 episode score is 0.69\n",
      "30:: 63488 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "31:: 65536 episode score is 0.69\n",
      "31:: 65536 episode similarity score is -0.00\n",
      "Expert: 0.00% | Learner: 100.00%\n",
      "32:: 67584 episode score is 0.69\n",
      "32:: 67584 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n",
      "33:: 69632 episode score is 0.69\n",
      "33:: 69632 episode similarity score is -0.00\n",
      "Expert: 100.00% | Learner: 0.00%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python ../src/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
